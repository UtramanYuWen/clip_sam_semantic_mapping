#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€æ¨¡å—ã€‘SAMå›¾åƒåˆ†å‰²å™¨ (Meta Segment Anything)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ã€åŠŸèƒ½æè¿°ã€‘
åŸºäºMetaçš„Segment Anything (SAM) æ¨¡å‹ï¼Œè¿›è¡Œé«˜è´¨é‡çš„å›¾åƒå®ä¾‹åˆ†å‰²ï¼š
  âœ“ è‡ªåŠ¨å®ä¾‹åˆ†å‰²: æ— éœ€æç¤ºå³å¯åˆ†å‰²æ‰€æœ‰ç‰©ä½“
  âœ“ å¿«é€Ÿæ¨ç†: ä¼˜åŒ–çš„æ©ç ç”Ÿæˆç®¡é“
  âœ“ å¤šå°ºåº¦åˆ†å‰²: å¤„ç†ä¸åŒå°ºåº¦çš„ç‰©ä½“
  âœ“ ç‚¹æç¤ºåˆ†å‰²: æ”¯æŒäº¤äº’å¼åˆ†å‰²

ã€ä¸»è¦ç±»ã€‘
  - SAMSegmentation: å›¾åƒåˆ†å‰²æ ¸å¿ƒç±»

ã€æ ¸å¿ƒæ–¹æ³•ã€‘
  - __init__: åˆå§‹åŒ–SAMæ¨¡å‹
  - _init_sam_model: åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å’Œç”Ÿæˆå™¨
  - segment: æ‰§è¡Œè‡ªåŠ¨åˆ†å‰²
  - segment_from_prompts: åŸºäºæç¤ºç‚¹çš„åˆ†å‰²
  - get_masks_by_category: æŒ‰è¯­ä¹‰ç±»åˆ«è¿‡æ»¤æ©ç 

ã€å·¥ä½œåŸç†ã€‘
  1. åŠ è½½SAMé¢„è®­ç»ƒæ¨¡å‹ (ViT-Bæˆ–ViT-L)
  2. è¾“å…¥å›¾åƒåˆ°SamAutomaticMaskGenerator
  3. ç”Ÿæˆå™¨è‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„å®ä¾‹æ©ç 
  4. æ¯ä¸ªæ©ç åŒ…å«ä½ç½®ã€å¤§å°ã€ç½®ä¿¡åº¦ç­‰ä¿¡æ¯
  5. å¯é€‰: åŸºäºCLIPç‰¹å¾è¿‡æ»¤å’Œåˆ†ç±»æ©ç 

ã€åˆ†å‰²å‚æ•°ã€‘
  - points_per_side: é‡‡æ ·ç‚¹å¯†åº¦ (é»˜è®¤16)
  - pred_iou_thresh: é¢„æµ‹IOUé˜ˆå€¼ (é»˜è®¤0.7)
  - stability_score_thresh: ç¨³å®šæ€§é˜ˆå€¼ (é»˜è®¤0.8)
  - crop_n_layers: å¤šå±‚è£å‰ªå±‚æ•° (é»˜è®¤1)
  - min_mask_region_area: æœ€å°æ©ç é¢ç§¯ (é»˜è®¤500åƒç´ )

ã€æ”¯æŒçš„æ¨¡å‹ã€‘
  - vit_b: Vision Transformer Base (æ¨èï¼Œå¿«é€Ÿ)
  - vit_l: Vision Transformer Large (ç²¾å‡†ï¼Œæ…¢é€Ÿ)
  - vit_h: Vision Transformer Huge (æœ€ç²¾å‡†ï¼Œæœ€æ…¢)

ã€è¾“å‡ºæ ¼å¼ã€‘
  æ¯ä¸ªæ©ç åŒ…å«:
  - segmentation: äºŒå€¼æ©ç  (H Ã— W)
  - area: æ©ç åƒç´ é¢ç§¯
  - bbox: è¾¹ç•Œæ¡† [x, y, w, h]
  - predicted_iou: é¢„æµ‹çš„IOUåˆ†æ•°
  - stability_score: åˆ†å‰²ç¨³å®šæ€§åˆ†æ•°
  - crop_box: è£å‰ªæ¡†

ã€æ€§èƒ½æŒ‡æ ‡ã€‘
  - å•å¼ å›¾åƒåˆ†å‰²æ—¶é—´: ~0.5-2ç§’ (GPU, å–å†³äºæ¨¡å‹)
  - è¾“å‡ºæ©ç æ•°é‡: 10-500ä¸ª (å–å†³äºå›¾åƒå¤æ‚åº¦)
  - å†…å­˜å ç”¨: ~4GB (ViT-B) åˆ° ~10GB (ViT-H)

ã€é…ç½®å‚æ•°ã€‘
  ä» config/clip_sam_config.yaml è¯»å–:
  - sam.model_type: æ¨¡å‹ç‰ˆæœ¬ (vit_b/vit_l/vit_h)
  - sam.checkpoint_path: æ¨¡å‹æƒé‡è·¯å¾„
  - sam.points_per_side: é‡‡æ ·ç‚¹æ•°
  - sam.pred_iou_thresh: é¢„æµ‹é˜ˆå€¼
  - sam.stability_score_thresh: ç¨³å®šæ€§é˜ˆå€¼
  - sam.min_mask_region_area: æœ€å°åŒºåŸŸé¢ç§¯

ã€ä½¿ç”¨ç¤ºä¾‹ã€‘
  sam = SAMSegmentation(config_path)
  masks = sam.segment(image_array)
  for mask in masks:
      print(f"æ©ç é¢ç§¯: {mask['area']}, IOU: {mask['predicted_iou']}")

ã€æ³¨æ„äº‹é¡¹ã€‘
  - é¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹æƒé‡ (~375MB)
  - GPUå¼ºçƒˆæ¨è (CPUæ¨ç†ææ…¢)
  - è¾“å…¥å›¾åƒåˆ†è¾¨ç‡è¶Šé«˜ï¼Œåˆ†å‰²æ•ˆæœè¶Šå¥½ä½†é€Ÿåº¦è¶Šæ…¢
  - å¯ç¼“å­˜è®¡ç®—ç»“æœä»¥åŠ é€Ÿé‡å¤æ¨ç†

ã€ç‰ˆæœ¬ä¿¡æ¯ã€‘
  - å½“å‰ç‰ˆæœ¬: 3.0
  - SAMç‰ˆæœ¬: Meta Segment Anything v1.0
  - æœ€åæ›´æ–°: 2025å¹´12æœˆ9æ—¥
"""

import numpy as np
import cv2
from PIL import Image as PILImage
import torch
import yaml
import os
from typing import List, Dict, Any, Optional

try:
    from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor
    SAM_AVAILABLE = True
except ImportError:
    print("âš ï¸  SAMæœªå®‰è£…ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿåˆ†å‰²")
    SAM_AVAILABLE = False

class SAMSegmentation:
    def __init__(self, config_path: str = None):
        # åŠ è½½é…ç½®
        if config_path is None:
            current_dir = os.path.dirname(os.path.abspath(__file__))
            config_path = os.path.join(current_dir, "../config/clip_sam_config.yaml")
        
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        # è®¾å¤‡é…ç½®
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ğŸ”¥ SAMä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # SAMé…ç½®
        sam_config = self.config['sam']
        self.model_type = sam_config['model_type']
        self.checkpoint_path = sam_config['checkpoint_path']
        
        self.sam_available = SAM_AVAILABLE and os.path.exists(self.checkpoint_path)
        
        if self.sam_available:
            self._init_sam_model(sam_config)
        else:
            print("âš ï¸  SAMä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿåˆ†å‰²")
            self.mask_generator = None
            self.predictor = None
        
        self.last_processed_image = None
        self.cached_masks = None
    
    def _init_sam_model(self, sam_config: Dict[str, Any]):
        """åˆå§‹åŒ–SAMæ¨¡å‹"""
        try:
            # åŠ è½½SAMæ¨¡å‹
            print(f"ğŸ”„ åŠ è½½SAMæ¨¡å‹: {self.model_type}")
            self.sam = sam_model_registry[self.model_type](checkpoint=self.checkpoint_path)
            self.sam.to(device=self.device)
            print("âœ… SAMæ¨¡å‹åŠ è½½å®Œæˆ")
            
            # è‡ªåŠ¨æ©ç ç”Ÿæˆå™¨
            self.mask_generator = SamAutomaticMaskGenerator(
                model=self.sam,
                points_per_side=sam_config.get('points_per_side', 16),
                pred_iou_thresh=sam_config.get('pred_iou_thresh', 0.7),
                stability_score_thresh=sam_config.get('stability_score_thresh', 0.8),
                crop_n_layers=sam_config.get('crop_n_layers', 1),
                crop_n_points_downscale_factor=sam_config.get('crop_n_points_downscale_factor', 2),
                min_mask_region_area=sam_config.get('min_mask_region_area', 500),
            )
            
            # é¢„æµ‹å™¨
            self.predictor = SamPredictor(self.sam)
            
        except Exception as e:
            print(f"âŒ SAMåˆå§‹åŒ–å¤±è´¥: {e}")
            self.sam_available = False
            self.mask_generator = None
            self.predictor = None
    
    def generate_masks(self, image: np.ndarray, 
                      use_cache: bool = True) -> List[Dict[str, Any]]:
        """
        ç”Ÿæˆå›¾åƒåˆ†å‰²æ©ç 
        
        Args:
            image: RGBæ ¼å¼çš„numpyæ•°ç»„
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            
        Returns:
            æ©ç åˆ—è¡¨
        """
        try:
            if not self.sam_available:
                return self._generate_mock_masks(image)
            
            # æ£€æŸ¥ç¼“å­˜
            if use_cache and self._can_use_cache(image):
                print("   ğŸš€ ä½¿ç”¨SAMæ©ç ç¼“å­˜")
                return self.cached_masks
            
            print("   ğŸ” SAMç”Ÿæˆæ–°æ©ç ...")
            
            # ç”Ÿæˆåˆ†å‰²æ©ç 
            masks = self.mask_generator.generate(image)
            
            # æŒ‰é¢ç§¯æ’åºå¹¶è¿‡æ»¤
            masks = sorted(masks, key=lambda x: x['area'], reverse=True)
            min_area = self.config['sam'].get('min_mask_region_area', 500)
            filtered_masks = [mask for mask in masks if mask['area'] >= min_area]
            
            # æ›´æ–°ç¼“å­˜
            if use_cache:
                self.last_processed_image = image.copy()
                self.cached_masks = filtered_masks
            
            print(f"   âœ… SAMç”Ÿæˆ {len(filtered_masks)} ä¸ªæœ‰æ•ˆæ©ç ")
            return filtered_masks
            
        except Exception as e:
            print(f"âŒ SAMæ©ç ç”Ÿæˆé”™è¯¯: {e}")
            return self._generate_mock_masks(image)
    
    def _generate_mock_masks(self, image: np.ndarray) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ¨¡æ‹Ÿæ©ç ï¼ˆå½“SAMä¸å¯ç”¨æ—¶ï¼‰"""
        try:
            h, w = image.shape[:2]
            
            # åˆ›å»ºå‡ ä¸ªç®€å•çš„çŸ©å½¢åŒºåŸŸä½œä¸ºæ©ç 
            masks = []
            
            # ä¸­å¤®å¤§åŒºåŸŸ
            mask1 = np.zeros((h, w), dtype=bool)
            mask1[h//4:3*h//4, w//4:3*w//4] = True
            masks.append({
                'segmentation': mask1,
                'area': np.sum(mask1),
                'bbox': [w//4, h//4, w//2, h//2],
                'predicted_iou': 0.8
            })
            
            # å·¦ä¸Šè§’åŒºåŸŸ
            mask2 = np.zeros((h, w), dtype=bool)
            mask2[0:h//2, 0:w//2] = True
            masks.append({
                'segmentation': mask2,
                'area': np.sum(mask2),
                'bbox': [0, 0, w//2, h//2],
                'predicted_iou': 0.7
            })
            
            print(f"   ğŸ”„ ç”Ÿæˆ {len(masks)} ä¸ªæ¨¡æ‹Ÿæ©ç ")
            return masks
            
        except Exception as e:
            print(f"âŒ æ¨¡æ‹Ÿæ©ç ç”Ÿæˆé”™è¯¯: {e}")
            return []
    
    def _can_use_cache(self, image: np.ndarray) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥ä½¿ç”¨ç¼“å­˜"""
        if (self.last_processed_image is None or 
            self.cached_masks is None):
            return False
        
        try:
            # å¿«é€Ÿç›¸ä¼¼æ€§æ£€æŸ¥
            small_current = cv2.resize(image, (64, 64))
            small_last = cv2.resize(self.last_processed_image, (64, 64))
            
            diff = cv2.absdiff(small_current, small_last)
            diff_mean = np.mean(diff)
            
            return diff_mean < 10
            
        except:
            return False
    
    def segment_with_points(self, image: np.ndarray, 
                           points: List[List[int]], 
                           labels: List[int]) -> Dict[str, Any]:
        """åŸºäºæŒ‡å®šç‚¹è¿›è¡Œåˆ†å‰²"""
        try:
            if not self.sam_available:
                return self._mock_point_segmentation(image, points)
            
            self.predictor.set_image(image)
            
            input_points = np.array(points)
            input_labels = np.array(labels)
            
            masks, scores, logits = self.predictor.predict(
                point_coords=input_points,
                point_labels=input_labels,
                multimask_output=True
            )
            
            # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„æ©ç 
            best_idx = np.argmax(scores)
            best_mask = masks[best_idx]
            best_score = scores[best_idx]
            
            return {
                'segmentation': best_mask,
                'score': best_score,
                'area': np.sum(best_mask),
                'bbox': self._mask_to_bbox(best_mask)
            }
            
        except Exception as e:
            print(f"âŒ SAMç‚¹åˆ†å‰²é”™è¯¯: {e}")
            return self._mock_point_segmentation(image, points)
    
    def _mock_point_segmentation(self, image: np.ndarray, points: List[List[int]]) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿç‚¹åˆ†å‰²"""
        h, w = image.shape[:2]
        mask = np.zeros((h, w), dtype=bool)
        
        # åœ¨æ¯ä¸ªç‚¹å‘¨å›´åˆ›å»ºåœ†å½¢åŒºåŸŸ
        for point in points:
            x, y = point
            radius = min(50, min(w, h) // 10)
            cv2.circle(mask.astype(np.uint8), (x, y), radius, 1, -1)
        
        mask = mask.astype(bool)
        
        return {
            'segmentation': mask,
            'score': 0.8,
            'area': np.sum(mask),
            'bbox': self._mask_to_bbox(mask)
        }
    
    def _mask_to_bbox(self, mask: np.ndarray) -> List[int]:
        """æ©ç è½¬è¾¹ç•Œæ¡†"""
        try:
            y_indices, x_indices = np.where(mask)
            if len(x_indices) == 0:
                return [0, 0, 0, 0]
            
            x_min, x_max = np.min(x_indices), np.max(x_indices)
            y_min, y_max = np.min(y_indices), np.max(y_indices)
            
            return [int(x_min), int(y_min), int(x_max - x_min), int(y_max - y_min)]
        except:
            return [0, 0, 0, 0]

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    sam = SAMSegmentation()
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
    
    # æµ‹è¯•æ©ç ç”Ÿæˆ
    masks = sam.generate_masks(test_image)
    print(f"ç”Ÿæˆæ©ç æ•°é‡: {len(masks)}")
    
    if len(masks) > 0:
        print(f"æœ€å¤§æ©ç é¢ç§¯: {masks[0]['area']}")