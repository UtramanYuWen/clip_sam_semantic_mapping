#!/usr/bin/env python3  
# -*- coding: utf-8 -*-  
"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€ä¸»ç³»ç»Ÿã€‘å¤šå±‚æ¬¡CLIP+SAMè¯­ä¹‰å»ºå›¾æ ¸å¿ƒæ¨¡å—
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ã€åŠŸèƒ½æè¿°ã€‘
æ­¤æ¨¡å—æ˜¯æ•´ä¸ªè¯­ä¹‰å»ºå›¾ç³»ç»Ÿçš„æ ¸å¿ƒï¼Œå®ç°äº†å®Œæ•´çš„å¤šå±‚æ¬¡è¯­ä¹‰åˆ†ææµç¨‹ï¼š
  âœ“ æˆ¿é—´è¯†åˆ« (CLIP) - 8ç§æˆ¿é—´ç±»å‹å®æ—¶åˆ†ç±»
  âœ“ å®¶å…·æ£€æµ‹ (CLIP+SAM) - 30+ç§å®¶å…·å¯¹è±¡è¯†åˆ«
  âœ“ ç»“æ„åˆ†å‰² (SAM) - å¢™å£ã€é—¨ã€çª—ç­‰ç»“æ„å…ƒç´ åˆ†å‰²
  âœ“ å¯¼èˆªè·¯ç‚¹ç”Ÿæˆ - è‡ªåŠ¨ç”ŸæˆPGMã€YAMLã€XMLæ ¼å¼åœ°å›¾

ã€ä¸»è¦ç±»ã€‘
  - HierarchicalCLIPSAMMapping: ä¸»ç³»ç»Ÿç±»ï¼Œç®¡ç†æ•´ä¸ªè¯­ä¹‰å»ºå›¾æµç¨‹

ã€å·¥ä½œæµç¨‹ã€‘
  1. åˆå§‹åŒ– â†’ åŠ è½½é…ç½®ã€åˆå§‹åŒ–CLIPå’ŒSAMæ¨¡å‹
  2. è®¢é˜…ROSè¯é¢˜ â†’ æ¥æ”¶ç›¸æœºå›¾åƒå’Œæ¿€å…‰é›·è¾¾æ•°æ®
  3. å®æ—¶æ¨ç† â†’ å®šæ—¶æ‰§è¡Œè¯­ä¹‰åˆ†æï¼ˆæˆ¿é—´+å®¶å…·+ç»“æ„ï¼‰
  4. ç”Ÿæˆåœ°å›¾ â†’ äº§ç”Ÿå¤šå±‚è¯­ä¹‰åœ°å›¾å’Œå¯¼èˆªè·¯ç‚¹
  5. å¯è§†åŒ– â†’ é€šè¿‡RVizå’ŒPNGè¾“å‡ºå±•ç¤ºç»“æœ

ã€ROSè¯é¢˜ã€‘
è®¢é˜…:
  - /camera/rgb/image_raw: RGBå›¾åƒè¾“å…¥
  - /scan: æ¿€å…‰é›·è¾¾æ‰«ææ•°æ®
  - /map: SLAMç”Ÿæˆçš„å ç”¨æ …æ ¼åœ°å›¾
å‘å¸ƒ:
  - /semantic_map/room: æˆ¿é—´è¯­ä¹‰åœ°å›¾
  - /semantic_map/furniture: å®¶å…·è¯­ä¹‰åœ°å›¾
  - /semantic_map/structure: ç»“æ„è¯­ä¹‰åœ°å›¾
  - /waypoints: å¯¼èˆªè·¯ç‚¹

ã€é…ç½®æ–‡ä»¶ã€‘
  - config/clip_sam_config.yaml: æ¨¡å‹å‚æ•°ã€æ¨ç†è®¾ç½®ã€æˆ¿é—´å®¶å…·åˆ—è¡¨

ã€æ€§èƒ½æŒ‡æ ‡ã€‘
  - å•å¸§å¤„ç†æ—¶é—´: <500ms (GPUç¯å¢ƒ)
  - æ¨ç†é¢‘ç‡: ~12Hz (åœ¨inference_interval=0.08sæ—¶)
  - æ”¯æŒæˆ¿é—´ç±»å‹: 8ç§ (å®¢å…ã€å§å®¤ã€å¨æˆ¿ã€å«ç”Ÿé—´ã€ä¹¦æˆ¿ã€é¤å…ã€é˜³å°ã€ç„å…³)
  - æ”¯æŒå®¶å…·å¯¹è±¡: 30+ç§
  - ç»“æ„å…ƒç´ : å¢™ã€é—¨ã€çª—ã€åœ°æ¿ã€å¤©èŠ±æ¿ã€æ¥¼æ¢¯ç­‰

ã€ä½¿ç”¨åœºæ™¯ã€‘
  - åœºæ™¯1: ä¸€ä½“åŒ–å¯åŠ¨ (hierarchical_clip_sam_mapping.launch)
    å•ä¸ªç»ˆç«¯å¯åŠ¨å®Œæ•´ç³»ç»Ÿï¼ŒåŒ…å«ä»¿çœŸã€SLAMã€è¯­ä¹‰åˆ†æã€RViz
  - åœºæ™¯2: åˆ†æ­¥å¯åŠ¨ (wpb_stage_robocup_custom.launch + semantic_only.launch)
    çµæ´»æ§åˆ¶ï¼Œä¾¿äºå¼€å‘å’Œè°ƒè¯•

ã€ç‰ˆæœ¬ä¿¡æ¯ã€‘
  - å½“å‰ç‰ˆæœ¬: 3.0 Production Ready
  - æœ€åæ›´æ–°: 2025å¹´12æœˆ9æ—¥
  - è¯­è¨€: Python 3.7+
  - ä¾èµ–: PyTorch, OpenAI CLIP, Meta SAM, ROS

ã€å¼€å‘æ³¨æ„ã€‘
  - æ‰€æœ‰ä¸»è¦å‡½æ•°éƒ½æœ‰ä¸­æ–‡æ³¨é‡Šè¯´æ˜
  - ä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„é”æœºåˆ¶ä¿æŠ¤å…±äº«æ•°æ®
  - é‡‡ç”¨å¤šè¿›ç¨‹æ¶æ„ä¼˜åŒ–æ¨ç†é€Ÿåº¦
  - æ”¯æŒå®æ—¶æ€§èƒ½ç›‘æ§å’Œç»Ÿè®¡
"""  

import rospy  
import numpy as np  
from sensor_msgs.msg import Image, LaserScan  
from nav_msgs.msg import OccupancyGrid  
from std_msgs.msg import String  
from cv_bridge import CvBridge  
import tf  
import cv2  
from PIL import Image as PILImage  
import os  
import time  
import threading  
import json  
import math  
import copy  
from datetime import datetime  
from scipy import ndimage  
import sys  

# æ·»åŠ è·¯å¾„  
sys.path.append(os.path.dirname(os.path.abspath(__file__)))  

# å¯¼å…¥æ¨¡å—  
from utils.config_loader import ConfigLoader  
from utils.image_utils import ImageProcessor  
from utils.path_manager import get_path_manager  
from clip_room_classifier import CLIPRoomClassifier  
from sam_segmentation import SAMSegmentation  
from furniture_structure_detector import FurnitureStructureDetector  
from waypoint_generator import WaypointGenerator  
from performance_optimizer import (  
    DisplayBuffer, ImageResizer, FPSCounter, MapUpdateOptimizer,  
    InferenceScheduler, SystemMonitor  
)
# âœ¨ ä¼˜åŒ–æ¨¡å—å¯¼å…¥æš‚æ—¶ç¦ç”¨ - ä¼šåœ¨AIæ¨¡å‹åˆå§‹åŒ–ååŠ¨æ€å¯¼å…¥
OPTIMIZATION_ENABLED = False  

class HierarchicalCLIPSAMMapping:  
    def __init__(self, config_path: str = None):  
        print("ğŸ åˆå§‹åŒ–å¤šå±‚æ¬¡CLIP+SAMè¯­ä¹‰å»ºå›¾ç³»ç»Ÿ...")  
        
        # åŠ è½½é…ç½®  
        self.config = ConfigLoader(config_path)  
        
        # æˆ¿é—´ç±»å‹ - ä»é…ç½®æ–‡ä»¶åŠ è½½  
        self.ROOM_TYPES = self.config.get('room_types.chinese', [  
            "å®¢å…", "å§å®¤", "å¨æˆ¿", "å«ç”Ÿé—´", "é˜³å°", "ä¹¦æˆ¿", "é¤å…", "ç„å…³"  
        ])  
        
        # âœ¨æ–°å¢ï¼šå®¶å…·å’Œç»“æ„ç±»åˆ«  
        self.furniture_config = self.config.get('furniture_objects', {})  
        self.structure_config = self.config.get('structural_elements', {})  
        
        # === æ¨ç†æ§åˆ¶ ===  
        self.INFERENCE_INTERVAL = self.config.get('inference.inference_interval', 0.08)  
        self.last_inference_time = 0  
        self.is_inferencing = False  
        
        # === å›¾åƒå’Œæ¿€å…‰æ•°æ® ===  
        self.latest_image = None  
        self.latest_laser_scan = None  
        self.image_received = False  
        self.laser_received = False  
        
        # === å®æ—¶æ¨ç†ç»“æœ ===  
        self.current_room = "æœªçŸ¥"  
        self.current_confidence = -1.0  
        
        # âœ¨æ–°å¢ï¼šå¤šå±‚æ¬¡æ£€æµ‹ç»“æœ  
        self.current_furniture = {}  
        self.current_structures = {}  
        self.detection_history = []  
        
        self.confidence_threshold = self.config.get('clip.confidence_threshold', 0.12)  
        
        # ğŸ“Œ ä½¿ç”¨è·¯å¾„ç®¡ç†å™¨è·å–ä¸´æ—¶ç›®å½•
        self.path_manager = get_path_manager()
        self.temp_dir = self.path_manager.get_temp_dir()  
        
        # === å¿«ç…§ç³»ç»Ÿ ===  
        self.current_snapshot = None  
        self.snapshot_lock = threading.Lock()  
        
        # === æ¿€å…‰é›·è¾¾æŠ•å°„å‚æ•° ===  
        self.lidar_range_min = self.config.get('laser_projection.range_min', 0.1)  
        self.lidar_angle_range = self.config.get('laser_projection.angle_range', 75.0)  
        
        # === åœ°å›¾ç›¸å…³ ===  
        self.occupancy_map = None  
        self.map_metadata = None  
        self.semantic_grid = None  
        
        # âœ¨æ–°å¢ï¼šå¤šå±‚æ¬¡è¯­ä¹‰ç½‘æ ¼  
        self.furniture_grid = None  
        self.structure_grid = None  
        
        self.room_coverage = {}  
        self.tf_listener = None  
        self.total_annotations = 0  
        
        # === è¯­ä¹‰åœ°å›¾ç”Ÿæˆ ===  
        self.semantic_map_image = None  
        self.raw_semantic_map_image = None  
        self.annotated_semantic_map_image = None  
        
        # âœ¨æ–°å¢ï¼šå¤šå±‚æ¬¡åœ°å›¾  
        self.furniture_map_image = None  
        self.structure_map_image = None  
        self.combined_map_image = None  
        
        self.region_centers = {}  
        self.map_generation_completed = False  
        
        # === æ–‡ä»¶åå­˜å‚¨ ===  
        self.saved_filenames = {  
            'original': None,  
            'intelligent': None,  
            'annotated': None,  
            'furniture': None,  
            'structure': None,  
            'combined': None  
        }  
        
        # æˆ¿é—´ç¼–ç å’Œé¢œè‰² - ä»é…ç½®æ–‡ä»¶åŠ è½½  
        self.room_codes = self.config.get('room_types.codes', {})  
        self.room_colors = self.config.get('room_types.colors', {})  
        
        # === ç»Ÿè®¡ä¿¡æ¯ ===  
        self.inference_count = 0  
        self.successful_snapshots = 0  
        self.failed_snapshots = 0  
        self.start_time = time.time()  
        
        # === æ˜¾ç¤ºç›¸å…³ ===  
        self.font = cv2.FONT_HERSHEY_SIMPLEX  
        self.font_scale = self.config.get('visualization.font_scale', 0.7)  
        self.font_thickness = self.config.get('visualization.font_thickness', 2)  
        
        # === RViz Imageå‘å¸ƒ ===  
        self.bridge = CvBridge()  
        
        # === ğŸš€ æ€§èƒ½ä¼˜åŒ–ç»„ä»¶åˆå§‹åŒ– ===  
        self.display_buffer = DisplayBuffer(max_size=2)
        self.image_resizer = ImageResizer()
        self.fps_counter = FPSCounter(window_size=30)
        self.map_update_optimizer = MapUpdateOptimizer(publish_interval=0.5)
        self.inference_scheduler = InferenceScheduler(
            base_interval=self.INFERENCE_INTERVAL,
            min_interval=0.05,
            max_interval=0.2
        )
        self.system_monitor = SystemMonitor()
        
        # === âœ¨ å‡†ç¡®ç‡ä¼˜åŒ–ç»„ä»¶åˆå§‹åŒ–ï¼ˆå»¶è¿Ÿåˆ°AIæ¨¡å‹åŠ è½½åï¼‰===
        self.furniture_vote_buffer = None
        self.region_room_classifier = None
        self.context_classifier = None
        self.furniture_verifier = None
        
        # æ€§èƒ½ç›‘æ§æ ‡å¿—
        self.show_performance_stats = False
        self.frame_processing_start = 0
        self.last_map_publish_time = 0
        self.map_publish_interval = 0.5  # 0.5ç§’å‘å¸ƒä¸€æ¬¡åœ°å›¾
        
        # ç³»ç»Ÿè¿è¡Œæ§åˆ¶  
        self.running = True  
        
        # åˆå§‹åŒ–æ ¸å¿ƒAIç»„ä»¶  
        print("ğŸ”„æ­£åœ¨åŠ è½½CLIP+SAM æ¨¡å‹...")  
        self._init_ai_models()  
        print("âœ…CLIP+SAMæ¨¡å‹åŠ è½½æˆåŠŸï¼")  
        print("ğŸš€æ€§èƒ½ä¼˜åŒ–å·²å¯ç”¨: å¼‚æ­¥æ˜¾ç¤ºã€åŠ¨æ€æ¨ç†è°ƒåº¦ã€åœ°å›¾æ›´æ–°ä¼˜åŒ–")
        print("ğŸ¨å¤šå±‚æ¬¡CLIP+SAMè¯­ä¹‰å»ºå›¾æ¨¡å¼(æˆ¿é—´+å®¶å…·+ç»“æ„)")  

    def _init_ai_models(self):  
        """åˆå§‹åŒ–AIæ¨¡å‹"""  
        try:  
            # åˆå§‹åŒ–CLIPåˆ†ç±»å™¨  
            self.clip_classifier = CLIPRoomClassifier()  
            
            # åˆå§‹åŒ–SAMåˆ†å‰²å™¨  
            self.sam_segmentation = SAMSegmentation()  
            
            # âœ¨åˆå§‹åŒ–å®¶å…·ç»“æ„æ£€æµ‹å™¨  
            self.furniture_structure_detector = FurnitureStructureDetector(  
                self.clip_classifier,   
                self.sam_segmentation,  
                self.config.config  
            )  
            
            # åˆå§‹åŒ–å›¾åƒå¤„ç†å™¨  
            self.image_processor = ImageProcessor()
            
            # âœ¨ç°åœ¨AIæ¨¡å‹å·²åˆå§‹åŒ–ï¼Œå¯ä»¥å®‰å…¨åœ°åˆå§‹åŒ–ä¼˜åŒ–æ¨¡å—
            try:
                from accuracy_improvement_modules import (
                    FurnitureVotingBuffer, RegionBasedRoomClassifier,
                    ContextAwareFurnitureClassifier, FurnitureGeometryVerifier
                )
                
                # å¤šå¸§å®¶å…·æŠ•ç¥¨ç¼“å†²ï¼ˆ7å¸§å†å²ï¼Œ60% æŠ•ç¥¨é˜ˆå€¼ï¼‰
                self.furniture_vote_buffer = FurnitureVotingBuffer(
                    window_size=7,
                    vote_threshold=0.6
                )
                
                # æˆ¿é—´åŒºåŸŸæŠ•ç¥¨åˆ†ç±»å™¨ï¼ˆ3x3 ç½‘æ ¼ï¼‰
                self.region_room_classifier = RegionBasedRoomClassifier(
                    self.clip_classifier,
                    grid_size=(3, 3)
                )
                
                # ä¸Šä¸‹æ–‡æ„ŸçŸ¥å®¶å…·åˆ†ç±»å™¨
                self.context_classifier = ContextAwareFurnitureClassifier(
                    self.clip_classifier,
                    self.config.config
                )
                
                # å®¶å…·å‡ ä½•éªŒè¯å™¨
                self.furniture_verifier = FurnitureGeometryVerifier()
                
                OPTIMIZATION_ENABLED = True
                print("âœ¨ä¼˜åŒ–æ¨¡å—åŠ è½½æˆåŠŸ")
                
            except Exception as e:
                print(f"âš ï¸ ä¼˜åŒ–æ¨¡å—åŠ è½½å¤±è´¥({e})ï¼Œå°†ä½¿ç”¨åŸå§‹æ¨ç†æ¨¡å¼")
                OPTIMIZATION_ENABLED = False
            
        except Exception as e:  
            print(f"âŒAIæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")  
            raise e  

    def initialize_ros(self):  
        """åˆå§‹åŒ–ROSç›¸å…³ç»„ä»¶"""  
        self.tf_listener = tf.TransformListener()  
        
        # è®¢é˜…è¯é¢˜ - ä»é…ç½®æ–‡ä»¶è·å–è¯é¢˜åç§°  
        topics = self.config.get('ros_topics', {})  
        
        self.image_sub = rospy.Subscriber(  
            topics.get('input_image', "/kinect2/qhd/image_color_rect"),   
            Image, self.image_callback, queue_size=1)  
        
        self.laser_sub = rospy.Subscriber(  
            topics.get('input_laser', "/scan"),   
            LaserScan, self.laser_callback, queue_size=1)  
        
        self.map_sub = rospy.Subscriber(  
            topics.get('input_map', '/map'),   
            OccupancyGrid, self.map_callback, queue_size=1)  
        
        # å‘å¸ƒè¯é¢˜  
        self.semantic_label_pub = rospy.Publisher(  
            topics.get('output_semantic_label', '/semantic_label'),   
            String, queue_size=1)  
        
        # âœ¨ä¿®å¤ï¼šæ­£ç¡®å‘å¸ƒè¯­ä¹‰å ç”¨æ …æ ¼  
        self.semantic_map_pub = rospy.Publisher(  
            topics.get('output_semantic_map', '/semantic_occupancy_grid'),   
            OccupancyGrid, queue_size=1)  
        
        self.semantic_image_pub = rospy.Publisher(  
            topics.get('output_semantic_image', '/semantic_map_image'),   
            Image, queue_size=1)  
        
        self.inference_info_pub = rospy.Publisher(  
            topics.get('output_inference_info', '/semantic_inference_info'),   
            String, queue_size=1)  
        
        # âœ¨æ–°å¢ï¼šå¤šå±‚æ¬¡è¯­ä¹‰å‘å¸ƒ  
        self.furniture_map_pub = rospy.Publisher(  
            topics.get('output_furniture_map', '/furniture_semantic_map'),   
            Image, queue_size=1)  
        
        self.structure_map_pub = rospy.Publisher(  
            topics.get('output_structure_map', '/structure_semantic_map'),   
            Image, queue_size=1)  
        
        rospy.loginfo("ğŸš€å¤šå±‚æ¬¡CLIP+SAMè¯­ä¹‰å»ºå›¾ç³»ç»Ÿå¯åŠ¨")  
        rospy.loginfo("ğŸ¯ç‰¹æ€§: CLIPæˆ¿é—´è¯†åˆ«+å®¶å…·æ£€æµ‹+ç»“æ„åˆ†æ+SAMå›¾åƒåˆ†å‰²")  

    def ros_image_to_cv2(self, ros_image):  
        """è½¬æ¢ROS Imageåˆ°CV2"""  
        try:  
            height = ros_image.height  
            width = ros_image.width  
            encoding = ros_image.encoding  
            
            if encoding == "bgr8":  
                np_arr = np.frombuffer(ros_image.data, dtype=np.uint8)  
                cv_image = np_arr.reshape((height, width, 3))  
            elif encoding == "rgb8":  
                np_arr = np.frombuffer(ros_image.data, dtype=np.uint8)  
                cv_image = np_arr.reshape((height, width, 3))  
                cv_image = cv2.cvtColor(cv_image, cv2.COLOR_RGB2BGR)  
            elif encoding == "mono8":  
                np_arr = np.frombuffer(ros_image.data, dtype=np.uint8)  
                cv_image = np_arr.reshape((height, width))  
                cv_image = cv2.cvtColor(cv_image, cv2.COLOR_GRAY2BGR)  
            else:  
                return None  
            
            return cv_image  
        except Exception as e:  
            rospy.logerr(f"å›¾åƒè½¬æ¢é”™è¯¯: {e}")  
            return None  

    def image_callback(self, data):  
        """å›¾åƒå›è°ƒå‡½æ•°"""  
        try:  
            cv_image = self.ros_image_to_cv2(data)  
            if cv_image is None:  
                return  
            
            self.latest_image = cv_image.copy()  
            self.image_received = True  
            
            # æ¨ç†æ§åˆ¶ - å®šæ—¶æ‰§è¡Œæ¨ç†  
            current_time = time.time()  
            if (current_time - self.last_inference_time >= self.INFERENCE_INTERVAL   
                and not self.is_inferencing):  
                self._direct_inference_and_annotation(cv_image.copy())  
                self.last_inference_time = current_time  
                
        except Exception as e:  
            rospy.logerr(f"å›¾åƒå›è°ƒé”™è¯¯: {e}")  

    def laser_callback(self, data):  
        """æ¿€å…‰é›·è¾¾å›è°ƒå‡½æ•°"""  
        try:  
            self.latest_laser_scan = data  
            self.laser_received = True  
        except Exception as e:  
            rospy.logerr(f"æ¿€å…‰é›·è¾¾å›è°ƒé”™è¯¯: {e}")  

    def map_callback(self, msg):  
        """å¤„ç†gmappingçš„åœ°å›¾æ•°æ® - æ”¯æŒå¤šå±‚æ¬¡è¯­ä¹‰"""  
        try:  
            self.occupancy_map = msg  
            self.map_metadata = msg.info  
            
            if self.semantic_grid is None:  
                # åˆå§‹åŒ–æ‰€æœ‰è¯­ä¹‰ç½‘æ ¼ - ä½¿ç”¨uint8é¿å…æº¢å‡º  
                grid_shape = (msg.info.height, msg.info.width)  
                self.semantic_grid = np.zeros(grid_shape, dtype=np.uint8)  # æˆ¿é—´(0-99)  
                self.furniture_grid = np.zeros(grid_shape, dtype=np.uint8)  # å®¶å…·(50-79)   
                self.structure_grid = np.zeros(grid_shape, dtype=np.uint8)  # ç»“æ„(80-99)  
                
                rospy.loginfo(f"ğŸ“å¤šå±‚æ¬¡è¯­ä¹‰æ …æ ¼: {msg.info.width} x {msg.info.height}")  
                rospy.loginfo(f"ğŸ æˆ¿é—´å±‚ + ğŸª‘å®¶å…·å±‚ + ğŸ§±ç»“æ„å±‚")  
                
        except Exception as e:  
            rospy.logerr(f"åœ°å›¾å›è°ƒé”™è¯¯: {e}")  

    def get_robot_pose(self):  
        """è·å–æœºå™¨äººåœ¨åœ°å›¾ä¸­çš„ä½ç½®å’Œæœå‘"""  
        try:  
            if self.tf_listener is None:  
                return None, None, None  
            
            self.tf_listener.waitForTransform('map', 'base_link', rospy.Time(0), rospy.Duration(0.1))  
            (trans, rot) = self.tf_listener.lookupTransform('map', 'base_link', rospy.Time(0))  
            
            world_x, world_y = trans[0], trans[1]  
            
            import tf.transformations  
            euler = tf.transformations.euler_from_quaternion(rot)  
            yaw = euler[2]  
            
            return world_x, world_y, yaw  
        except Exception as e:  
            return None, None, None  

    def _direct_inference_and_annotation(self, image):  
        """ğŸš€ä¼˜åŒ–ç‰ˆæ¨ç†å’Œæ ‡æ³¨ - å¤šå±‚æ¬¡è¯­ä¹‰åˆ†æ + æ€§èƒ½è°ƒåº¦"""  
        def inference_worker():  
            inference_start_time = time.time()
            try:  
                self.is_inferencing = True  
                
                robot_x, robot_y, robot_yaw = self.get_robot_pose()  
                if robot_x is None or self.latest_laser_scan is None:  
                    return  
                
                task_id = f"hierarchical_clip_sam_{int(time.time() * 1000)}"  
                
                projected_points = self._calculate_projected_points(  
                    robot_x, robot_y, robot_yaw, self.latest_laser_scan  
                )  
                
                if not projected_points:  
                    return  
                
                with self.snapshot_lock:  
                    self.current_snapshot = {  
                        'task_id': task_id,  
                        'projected_points': projected_points,  
                        'timestamp': time.time()  
                    }  
                
                # ğŸ æˆ¿é—´åˆ†æï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰  
                room_result = self._analyze_room_with_clip_sam(image)  
                
                # ğŸª‘ğŸ§±å®¶å…·å’Œç»“æ„åˆ†æ - ä»…åœ¨å¿…è¦æ—¶æ‰§è¡Œ
                if room_result != "æœªçŸ¥":  # åªåœ¨æˆ¿é—´è¯†åˆ«æˆåŠŸæ—¶åˆ†æå®¶å…·å’Œç»“æ„
                    furniture_structure_results = self._analyze_furniture_and_structures(image)  
                else:
                    furniture_structure_results = {
                        'furniture': {},
                        'structures': {},
                        'masks': {},
                        'confidence_scores': {}
                    }
                
                # åˆå¹¶åˆ†æç»“æœ  
                combined_results = {  
                    'room': room_result,  
                    'furniture': furniture_structure_results.get('furniture', {}),  
                    'structures': furniture_structure_results.get('structures', {}),  
                    'masks': furniture_structure_results.get('masks', {}),  
                    'confidence_scores': furniture_structure_results.get('confidence_scores', {})  
                }  
                
                # âœ¨ä¿®å¤ï¼šåˆ†å±‚æ ‡æ³¨å½“å‰å¿«ç…§  
                self._annotate_current_snapshot_hierarchical(combined_results)  
                
                self.inference_count += 1  
                
                # æ›´æ–°å½“å‰æ£€æµ‹çŠ¶æ€  
                self.current_furniture = combined_results['furniture']  
                self.current_structures = combined_results['structures']  
                
                # è®°å½•æ¨ç†æ—¶é—´
                inference_time = time.time() - inference_start_time
                self.system_monitor.record_inference_time(inference_time)
                
                # ä»…å¶å°”æ‰“å°æ—¥å¿—ï¼ˆå‡å°‘I/Oï¼‰
                if self.inference_count % 5 == 0:
                    print(f"âš¡æ¨ç†#{self.inference_count}: {room_result} ({inference_time:.2f}s)")
                    
            except Exception as e:  
                print(f"âŒå¤šå±‚æ¬¡æ¨ç†å¼‚å¸¸: {e}")  
                self.failed_snapshots += 1  
            finally:  
                self.is_inferencing = False  
        
        thread = threading.Thread(target=inference_worker, daemon=True)  
        thread.start()  

    def _analyze_room_with_clip_sam(self, image):  
        """ğŸ¯ä½¿ç”¨CLIP+SAMåˆ†ææˆ¿é—´ç±»å‹"""  
        try:  
            # è°ƒæ•´å›¾åƒå°ºå¯¸ä»¥æé«˜å¤„ç†é€Ÿåº¦  
            processed_image = self.image_processor.resize_image(image, 512)  
            
            # è½¬æ¢ä¸ºPILæ ¼å¼  
            pil_image = self.image_processor.cv2_to_pil(processed_image)  
            if pil_image is None:  
                self.current_confidence = 0.0  
                return "æœªçŸ¥"  
            
            # âœ¨ å°è¯•ä½¿ç”¨ä¼˜åŒ–çš„æˆ¿é—´åˆ†ç±»ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.region_room_classifier is not None:
                try:
                    room_result, confidence = self.region_room_classifier.classify_by_regions(
                        pil_image,
                        confidence_threshold=0.1  # ä½é˜ˆå€¼è·å–åŸå§‹åˆ†å¸ƒ
                    )
                except Exception as e:
                    print(f"âš ï¸ åŒºåŸŸæŠ•ç¥¨åˆ†ç±»å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹æ–¹å¼: {e}")
                    room_result, confidence = self.clip_classifier.classify_room(
                        pil_image, 0.0
                    )
            else:
                # åŸå§‹æ–¹å¼ï¼šå•ç‚¹CLIPåˆ†ç±»
                room_result, confidence = self.clip_classifier.classify_room(
                    pil_image, 0.0
                )
            
            # ä¿å­˜åŸå§‹ç½®ä¿¡åº¦  
            self.current_confidence = confidence  
            
            # ğŸ¯åº”ç”¨æˆ‘ä»¬çš„ç½®ä¿¡åº¦é˜ˆå€¼è¿›è¡Œå¼ºåˆ¶è¿‡æ»¤  
            if confidence < self.confidence_threshold:  
                room_result = "æœªçŸ¥"  
                print(f" ğŸ¯CLIPè¯†åˆ«: åŸå§‹ç»“æœè¢«è¿‡æ»¤(ç½®ä¿¡åº¦:{confidence:.3f} < é˜ˆå€¼:{self.confidence_threshold:.3f}) -> æœªçŸ¥")  
            else:  
                print(f" ğŸ¯CLIPè¯†åˆ«: {room_result} (ç½®ä¿¡åº¦:{confidence:.3f} >= é˜ˆå€¼:{self.confidence_threshold:.3f})")  
            
            # ğŸ”å¯é€‰: ä½¿ç”¨SAMå¢å¼ºåˆ†æ(å½“ç½®ä¿¡åº¦è¾ƒä½æ—¶)  
            if confidence < 0.3 and room_result == "æœªçŸ¥":  
                print(" ğŸ”å°è¯•SAMå¢å¼ºåˆ†æ...")  
                enhanced_result = self._enhance_with_sam(processed_image, room_result)  
                if enhanced_result != "æœªçŸ¥":  
                    print(f" ğŸ”SAMå¢å¼ºæˆåŠŸ: {enhanced_result}")  
                    room_result = enhanced_result  
                else:  
                    print(" ğŸ”SAMå¢å¼ºæ— æ•ˆæœ")  
            
            # ç¡®ä¿ç»“æœåœ¨æ”¯æŒçš„æˆ¿é—´ç±»å‹ä¸­  
            if room_result not in self.ROOM_TYPES and room_result != "æœªçŸ¥":  
                print(f" âš ï¸æˆ¿é—´ç±»å‹'{room_result}' ä¸åœ¨æ”¯æŒåˆ—è¡¨ä¸­ï¼Œè®¾ä¸ºæœªçŸ¥")  
                room_result = "æœªçŸ¥"  
            
            return room_result  
            
        except Exception as e:  
            print(f"âŒCLIP+SAMåˆ†æé”™è¯¯: {e}")  
            self.current_confidence = 0.0  
            return "æœªçŸ¥"  

    def _analyze_furniture_and_structures(self, image):  
        """åˆ†æå®¶å…·å’Œç»“æ„å…ƒç´ """  
        try:  
            # è°ƒæ•´å›¾åƒå°ºå¯¸  
            processed_image = self.image_processor.resize_image(image, 512)  
            
            # ä½¿ç”¨å®¶å…·ç»“æ„æ£€æµ‹å™¨ï¼ˆæ£€æŸ¥æ˜¯å¦ç¦ç”¨äº†Structureï¼‰
            structure_enabled = self.config.get('inference.structure_detection.enable', False)
            
            if structure_enabled:
                results = self.furniture_structure_detector.detect_furniture_and_structures(processed_image)
                furniture_results = results.get('furniture', {})
                structure_results = results.get('structures', {})
            else:
                # Structure ç¦ç”¨ï¼Œåªæ£€æµ‹å®¶å…·
                furniture_results = self.furniture_structure_detector._detect_furniture(
                    self.image_processor.cv2_to_pil(processed_image),
                    processed_image
                ).get('detections', {})
                structure_results = {}
            
            # âœ¨ å°è¯•ä½¿ç”¨å¤šå¸§æŠ•ç¥¨ç¼“å†²ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.furniture_vote_buffer is not None:
                try:
                    self.furniture_vote_buffer.add_detection(furniture_results)
                    voted_furniture = self.furniture_vote_buffer.get_voted_furniture()
                    print(f"  ğŸª‘æ£€æµ‹å®¶å…·: {len(furniture_results)}, æŠ•ç¥¨ç¡®è®¤: {len(voted_furniture)}")
                except Exception as e:
                    print(f"âš ï¸ å®¶å…·æŠ•ç¥¨å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹ç»“æœ: {e}")
                    voted_furniture = furniture_results
            else:
                # åŸå§‹æ–¹å¼ï¼šç›´æ¥ä½¿ç”¨æ£€æµ‹ç»“æœ
                voted_furniture = furniture_results
                print(f"  ğŸª‘æ£€æµ‹å®¶å…·: {len(furniture_results)}")
            
            if structure_enabled:
                print(f"  ğŸ§±æ£€æµ‹åˆ°ç»“æ„: {len(structure_results)}")  
            
            return {
                'furniture': voted_furniture,
                'structures': structure_results,
                'masks': results.get('masks', {}) if structure_enabled else {},
                'confidence_scores': results.get('confidence_scores', {}) if structure_enabled else {}
            }
        except Exception as e:  
            print(f"âŒå®¶å…·ç»“æ„åˆ†æé”™è¯¯: {e}")  
            return {'furniture': {}, 'structures': {}, 'masks': {}, 'confidence_scores': {}}  

    def _enhance_with_sam(self, image: np.ndarray, default_result: str) -> str:  
        """ä½¿ç”¨SAMå¢å¼ºæˆ¿é—´è¯†åˆ«"""  
        try:  
            print(" ğŸ”SAMå¢å¼ºåˆ†æä¸­...")  
            
            # ç”Ÿæˆåˆ†å‰²æ©ç   
            masks = self.sam_segmentation.generate_masks(image)  
            
            if len(masks) == 0:  
                return default_result  
            
            # åˆ†ææœ€å¤§çš„å‡ ä¸ªåŒºåŸŸ  
            best_result = default_result  
            best_confidence = 0  
            
            for i, mask_data in enumerate(masks[:2]):  # åªåˆ†æå‰2ä¸ªæœ€å¤§åŒºåŸŸ  
                if mask_data['area'] < 500:  
                    continue  
                
                # æå–æ©ç åŒºåŸŸ  
                mask = mask_data['segmentation']  
                masked_image = self.image_processor.apply_mask_to_image(image, mask)  
                
                # ç”¨CLIPåˆ†ææ©ç åŒºåŸŸ  
                pil_masked = self.image_processor.cv2_to_pil(masked_image)  
                if pil_masked is None:  
                    continue  
                
                region_result, region_confidence = self.clip_classifier.classify_room(  
                    pil_masked, 0.0  # ä½¿ç”¨0é˜ˆå€¼è·å–åŸå§‹ç½®ä¿¡åº¦  
                )  
                
                if region_confidence > best_confidence:  
                    best_confidence = region_confidence  
                    best_result = region_result  
            
            # å¯¹SAMå¢å¼ºçš„ç»“æœä¹Ÿåº”ç”¨é˜ˆå€¼  
            if best_confidence < self.confidence_threshold:  
                return default_result  
            
            return best_result  
            
        except Exception as e:  
            print(f"âŒSAMå¢å¼ºå¤±è´¥: {e}")  
            return default_result  

    def _calculate_projected_points(self, robot_x, robot_y, robot_yaw, laser_scan):  
        """è®¡ç®—æ¿€å…‰æŠ•å°„ç‚¹"""  
        try:  
            if self.map_metadata is None:  
                return []  
            
            projected_points = []  
            angle_min = laser_scan.angle_min  
            angle_increment = laser_scan.angle_increment  
            front_angle_range = math.radians(self.lidar_angle_range / 2)  
            
            # é¢„è®¡ç®—åœ°å›¾è½¬æ¢å‚æ•°  
            map_origin_x = self.map_metadata.origin.position.x  
            map_origin_y = self.map_metadata.origin.position.y  
            map_resolution = self.map_metadata.resolution  
            map_width = self.map_metadata.width  
            map_height = self.map_metadata.height  
            
            for i, range_val in enumerate(laser_scan.ranges):  
                if (range_val < self.lidar_range_min or   
                    math.isinf(range_val) or math.isnan(range_val)):  
                    continue  
                
                laser_angle = angle_min + i * angle_increment  
                if abs(laser_angle) > front_angle_range:  
                    continue  
                
                world_angle = robot_yaw + laser_angle  
                point_x = robot_x + range_val * math.cos(world_angle)  
                point_y = robot_y + range_val * math.sin(world_angle)  
                
                # è½¬æ¢ä¸ºåœ°å›¾åæ ‡  
                map_x = int((point_x - map_origin_x) / map_resolution)  
                map_y = int((point_y - map_origin_y) / map_resolution)  
                
                # è¾¹ç•Œæ£€æŸ¥  
                if 0 <= map_x < map_width and 0 <= map_y < map_height:  
                    projected_points.append({  
                        'map_x': map_x,  
                        'map_y': map_y,  
                        'distance': range_val,  
                        'world_x': point_x,  
                        'world_y': point_y  
                    })  
            
            return projected_points  
            
        except Exception as e:  
            rospy.logerr(f"æŠ•å°„è®¡ç®—é”™è¯¯: {e}")  
            return []  

    def _annotate_current_snapshot_hierarchical(self, combined_results):  
        """âœ¨ä¿®å¤ï¼šå¤šå±‚æ¬¡è¯­ä¹‰æ ‡æ³¨ - é˜²æ­¢é‡å¤æ ‡æ³¨"""  
        try:  
            # åŸæœ‰æˆ¿é—´æ ‡æ³¨é€»è¾‘  
            room_result = combined_results['room']  
            self._annotate_current_snapshot(room_result)  
            
            # âœ¨ä¿®å¤ï¼šåˆ†åˆ«æ ‡æ³¨å®¶å…·å’Œç»“æ„ï¼Œé¿å…é‡å¤  
            self._annotate_furniture_layer(combined_results)  
            self._annotate_structure_layer(combined_results)  
            
        except Exception as e:  
            print(f"âŒå¤šå±‚æ¬¡æ ‡æ³¨é”™è¯¯: {e}")  

    def _annotate_current_snapshot(self, room_result):  
        """æ ‡æ³¨å½“å‰å¿«ç…§ - æˆ¿é—´å±‚"""  
        try:  
            if self.current_room != room_result:  
                print(f"ğŸ æˆ¿é—´åˆ‡æ¢: {self.current_room} -> {room_result}")  
            
            self.current_room = room_result  
            
            semantic_msg = String()  
            semantic_msg.data = room_result  
            self.semantic_label_pub.publish(semantic_msg)  
            
            # ğŸ¯å¦‚æœæ˜¯"æœªçŸ¥"æˆ¿é—´ï¼Œä¸è¿›è¡Œåœ°å›¾æ ‡æ³¨  
            if room_result == "æœªçŸ¥":  
                print(f"  âš ï¸è·³è¿‡æ ‡æ³¨: æˆ¿é—´ç±»å‹ä¸ºæœªçŸ¥")  
                self.failed_snapshots += 1  
                return  
            
            with self.snapshot_lock:  
                if self.current_snapshot is None:  
                    return  
                
                projected_points = self.current_snapshot['projected_points']  
                task_id = self.current_snapshot['task_id']  
                
                if self.semantic_grid is None or self.occupancy_map is None:  
                    return  
                
                room_code = self.room_codes.get(room_result, 5)  
                annotated_cells = 0  
                annotation_radius = self.config.get('laser_projection.room_annotation_radius', 5)  
                
                for point in projected_points:  
                    map_x, map_y = point['map_x'], point['map_y']  
                    
                    for dy in range(-annotation_radius, annotation_radius + 1):  
                        for dx in range(-annotation_radius, annotation_radius + 1):  
                            target_x = map_x + dx  
                            target_y = map_y + dy  
                            
                            if (0 <= target_x < self.map_metadata.width and   
                                0 <= target_y < self.map_metadata.height):  
                                
                                occupancy_index = target_y * self.map_metadata.width + target_x  
                                if occupancy_index < len(self.occupancy_map.data):  
                                    occupancy_value = self.occupancy_map.data[occupancy_index]  
                                    if occupancy_value >= 0 and occupancy_value < 25:  
                                        self.semantic_grid[target_y, target_x] = room_code  
                                        annotated_cells += 1  
                
                self.total_annotations += annotated_cells  
                
                if room_result not in self.room_coverage:  
                    self.room_coverage[room_result] = 0  
                self.room_coverage[room_result] += annotated_cells  
                
                if annotated_cells > 0:  
                    self.successful_snapshots += 1  
                    print(f"âœ…æˆ¿é—´æ ‡æ³¨æˆåŠŸ: {len(projected_points)} æŠ•å°„ç‚¹-> {annotated_cells} åƒç´ ({task_id})")  
                else:  
                    self.failed_snapshots += 1  
                    print(f"âš ï¸æˆ¿é—´æ ‡æ³¨å¤±è´¥: æ— æœ‰æ•ˆåƒç´ ({task_id})")  
                    
        except Exception as e:  
            print(f"âŒæˆ¿é—´æ ‡æ³¨é”™è¯¯: {e}")  
            self.failed_snapshots += 1  

    def _annotate_furniture_layer(self, combined_results):  
        """âœ¨ä¿®å¤ï¼šæ ‡æ³¨å®¶å…·å±‚ - é¿å…é‡å¤æ ‡æ³¨æ‰€æœ‰å®¶å…·"""  
        try:  
            if not combined_results['furniture']:  
                return  
            
            with self.snapshot_lock:  
                if self.current_snapshot is None or self.furniture_grid is None:  
                    return  
                
                projected_points = self.current_snapshot['projected_points']  
                
                # âœ¨ä¿®å¤ï¼šåªæ ‡æ³¨ç½®ä¿¡åº¦æœ€é«˜çš„å‰3ä¸ªå®¶å…·ï¼Œé¿å…å…¨éƒ¨é‡å¤æ ‡æ³¨  
                furniture_sorted = sorted(  
                    combined_results['furniture'].items(),   
                    key=lambda x: x[1]['confidence'],   
                    reverse=True  
                )  
                
                for furniture_name, furniture_info in furniture_sorted[:3]:  # åªæ ‡æ³¨å‰3ä¸ª  
                    if furniture_info['confidence'] < 0.25:  # å®¶å…·ç½®ä¿¡åº¦é˜ˆå€¼  
                        continue  
                    
                    # è·å–å®¶å…·ç¼–ç   
                    furniture_code = self._get_furniture_code(furniture_name, furniture_info)  
                    if furniture_code is None:  
                        continue  
                    
                    # æ ‡æ³¨åŒºåŸŸï¼ˆä½¿ç”¨è¾ƒå°çš„åŠå¾„ï¼‰  
                    annotation_radius = self.config.get('laser_projection.furniture_annotation_radius', 3)  
                    annotated_cells = 0  
                    
                    # âœ¨ä¿®å¤ï¼šä¸ºä¸åŒå®¶å…·ä½¿ç”¨ä¸åŒçš„æŠ•å°„ç‚¹å­é›†  
                    furniture_index = list(combined_results['furniture'].keys()).index(furniture_name)  
                    point_subset = projected_points[furniture_index::3]  # æ¯3ä¸ªå–1ä¸ªï¼Œé¿å…é‡å¤  
                    
                    for point in point_subset:  
                        map_x, map_y = point['map_x'], point['map_y']  
                        
                        for dy in range(-annotation_radius, annotation_radius + 1):  
                            for dx in range(-annotation_radius, annotation_radius + 1):  
                                target_x = map_x + dx  
                                target_y = map_y + dy  
                                
                                if (0 <= target_x < self.map_metadata.width and   
                                    0 <= target_y < self.map_metadata.height):  
                                    
                                    occupancy_index = target_y * self.map_metadata.width + target_x  
                                    if occupancy_index < len(self.occupancy_map.data):  
                                        occupancy_value = self.occupancy_map.data[occupancy_index]  
                                        if occupancy_value >= 0 and occupancy_value < 25:  
                                            # åªæ ‡æ³¨æœªè¢«æ ‡æ³¨è¿‡çš„åƒç´   
                                            if self.furniture_grid[target_y, target_x] == 0:  
                                                self.furniture_grid[target_y, target_x] = furniture_code  
                                                annotated_cells += 1  
                    
                    if annotated_cells > 0:  
                        print(f"  ğŸª‘æ ‡æ³¨å®¶å…·: {furniture_name} -> {annotated_cells}åƒç´ ")  
                    
        except Exception as e:  
            print(f"âŒå®¶å…·å±‚æ ‡æ³¨é”™è¯¯: {e}")  

    def _annotate_structure_layer(self, combined_results):  
        """âœ¨ä¿®å¤ï¼šæ ‡æ³¨ç»“æ„å±‚ - é¿å…é‡å¤æ ‡æ³¨æ‰€æœ‰ç»“æ„"""  
        try:  
            if not combined_results['structures']:  
                return  
            
            with self.snapshot_lock:  
                if self.current_snapshot is None or self.structure_grid is None:  
                    return  
                
                projected_points = self.current_snapshot['projected_points']  
                
                # âœ¨ä¿®å¤ï¼šåªæ ‡æ³¨ç½®ä¿¡åº¦æœ€é«˜çš„å‰3ä¸ªç»“æ„  
                structure_sorted = sorted(  
                    combined_results['structures'].items(),   
                    key=lambda x: x[1]['confidence'],   
                    reverse=True  
                )  
                
                for structure_name, structure_info in structure_sorted[:3]:  # åªæ ‡æ³¨å‰3ä¸ª  
                    if structure_info['confidence'] < 0.30:  # ç»“æ„ç½®ä¿¡åº¦é˜ˆå€¼  
                        continue  
                    
                    # è·å–ç»“æ„ç¼–ç   
                    structure_code = self._get_structure_code(structure_name, structure_info)  
                    if structure_code is None:  
                        continue  
                    
                    # æ ‡æ³¨åŒºåŸŸï¼ˆä½¿ç”¨æ›´å°çš„åŠå¾„ï¼‰  
                    annotation_radius = self.config.get('laser_projection.structure_annotation_radius', 2)  
                    annotated_cells = 0  
                    
                    # âœ¨ä¿®å¤ï¼šä¸ºä¸åŒç»“æ„ä½¿ç”¨ä¸åŒçš„æŠ•å°„ç‚¹å­é›†  
                    structure_index = list(combined_results['structures'].keys()).index(structure_name)  
                    point_subset = projected_points[structure_index::4]  # æ¯4ä¸ªå–1ä¸ª  
                    
                    for point in point_subset:  
                        map_x, map_y = point['map_x'], point['map_y']  
                        
                        for dy in range(-annotation_radius, annotation_radius + 1):  
                            for dx in range(-annotation_radius, annotation_radius + 1):  
                                target_x = map_x + dx  
                                target_y = map_y + dy  
                                
                                if (0 <= target_x < self.map_metadata.width and   
                                    0 <= target_y < self.map_metadata.height):  
                                    
                                    occupancy_index = target_y * self.map_metadata.width + target_x  
                                    if occupancy_index < len(self.occupancy_map.data):  
                                        occupancy_value = self.occupancy_map.data[occupancy_index]  
                                        if occupancy_value >= 0 and occupancy_value < 25:  
                                            # åªæ ‡æ³¨æœªè¢«æ ‡æ³¨è¿‡çš„åƒç´   
                                            if self.structure_grid[target_y, target_x] == 0:  
                                                self.structure_grid[target_y, target_x] = structure_code  
                                                annotated_cells += 1  
                    
                    if annotated_cells > 0:  
                        print(f"  ğŸ§±æ ‡æ³¨ç»“æ„: {structure_name} -> {annotated_cells}åƒç´ ")  
                    
        except Exception as e:  
            print(f"âŒç»“æ„å±‚æ ‡æ³¨é”™è¯¯: {e}")  

    def _get_furniture_code(self, furniture_name, furniture_info):  
        """è·å–å®¶å…·ç¼–ç """  
        try:  
            category = furniture_info.get('category')  
            furniture_codes = self.furniture_config.get(category, {}).get('codes', {})  
            return furniture_codes.get(furniture_name)  
        except:  
            return None  

    def _get_structure_code(self, structure_name, structure_info):  
        """è·å–ç»“æ„ç¼–ç """  
        try:  
            category = structure_info.get('category')  
            structure_codes = self.structure_config.get(category, {}).get('codes', {})  
            return structure_codes.get(structure_name)  
        except:  
            return None  

    def _publish_semantic_occupancy_grid(self):  
        """âœ¨ä¿®å¤ï¼šå®æ—¶å‘å¸ƒè¯­ä¹‰å ç”¨æ …æ ¼åˆ°RViz - å€¼èŒƒå›´æ­£ç¡®"""  
        try:  
            if self.semantic_grid is None or self.occupancy_map is None:  
                return  
            
            # åˆ›å»ºè¯­ä¹‰å ç”¨æ …æ ¼æ¶ˆæ¯  
            semantic_grid_msg = OccupancyGrid()  
            semantic_grid_msg.header = self.occupancy_map.header  
            semantic_grid_msg.header.stamp = rospy.Time.now()  
            semantic_grid_msg.info = self.occupancy_map.info  
            
            # è½¬æ¢è¯­ä¹‰ç½‘æ ¼ä¸ºå ç”¨æ …æ ¼æ ¼å¼
            # âœ¨å…³é”®ä¿®å¤ï¼šæˆ¿é—´ç¼–ç æ˜ å°„åˆ° 0-100 èŒƒå›´
            height, width = self.semantic_grid.shape  
            semantic_data = []  
            
            # åˆ›å»ºæˆ¿é—´ç¼–ç åˆ°å ç”¨å€¼çš„æ˜ å°„
            room_code_to_occupancy = {}
            for room_name, room_code in self.room_codes.items():
                # æ˜ å°„åˆ° 25-100 èŒƒå›´ï¼ˆ25=ä½ç½®ä¿¡ï¼Œ100=é«˜ç½®ä¿¡ï¼‰
                occupancy_value = 25 + min(int(room_code * 0.75), 75)
                room_code_to_occupancy[room_code] = occupancy_value
            
            for y in range(height):  
                for x in range(width):  
                    # æˆ¿é—´è¯­ä¹‰å€¼  
                    room_code = int(self.semantic_grid[y, x])  
                    
                    if room_code == 0:  
                        # æœªæ ‡æ³¨åŒºåŸŸï¼Œä¿æŒåŸå§‹å ç”¨å€¼  
                        original_index = y * width + x  
                        if original_index < len(self.occupancy_map.data):  
                            semantic_data.append(self.occupancy_map.data[original_index])  
                        else:  
                            semantic_data.append(-1)  
                    else:  
                        # å·²æ ‡æ³¨åŒºåŸŸï¼Œä½¿ç”¨æ˜ å°„çš„å ç”¨å€¼
                        occupancy_value = room_code_to_occupancy.get(room_code, 50)  
                        semantic_data.append(occupancy_value)  
            
            semantic_grid_msg.data = semantic_data  
            self.semantic_map_pub.publish(semantic_grid_msg)  
            
        except Exception as e:  
            rospy.logwarn(f"è¯­ä¹‰æ …æ ¼å‘å¸ƒé”™è¯¯: {e}")  

    def draw_chinese_safe(self, img, text, pos, color, size=None):  
        """å®‰å…¨ç»˜åˆ¶ä¸­æ–‡æ–‡æœ¬ - è½¬æ¢ä¸ºè‹±æ–‡é¿å…ä¹±ç """  
        try:  
            if size is None:  
                size = self.font_scale  
            
            # ä¸­æ–‡æˆ¿é—´ç±»å‹æ˜ å°„  
            room_mapping = {  
                "å®¢å…": "Living Room",  
                "å§å®¤": "Bedroom",   
                "å¨æˆ¿": "Kitchen",  
                "å«ç”Ÿé—´": "Bathroom",  
                "é˜³å°": "Balcony",  
                "ä¹¦æˆ¿": "Study",  
                "é¤å…": "Dining Room",  
                "ç„å…³": "Entrance",  
                "æœªçŸ¥": "Unknown"  
            }  
            
            # ä¸­æ–‡å®¶å…·ç±»å‹æ˜ å°„ - å®Œæ•´ç‰ˆ
            furniture_mapping = {
                "è¡£æŸœ": "Wardrobe",
                "åºŠ": "Bed",
                "æ²™å‘": "Sofa",
                "æ¡Œå­": "Table",
                "æ¤…å­": "Chair",
                "ä¹¦æŸœ": "Bookshelf",
                "å‡³å­": "Stool",
                "åŠå…¬æ¡Œ": "Desk",
                "æ¢³å¦†å°": "Dressing Table",
                "é‹æŸœ": "Shoe Cabinet",
                "èŒ¶å‡ ": "Coffee Table",
                "é¤æ¡Œ": "Dining Table",
                "ç”µè§†æŸœ": "TV Stand",
                "ç”µè§†": "Television",
                "å†°ç®±": "Refrigerator",
                "æ´—è¡£æœº": "Washing Machine",
                "ç©ºè°ƒ": "Air Conditioner",
                "å¾®æ³¢ç‚‰": "Microwave",
                "çƒ­æ°´å™¨": "Water Heater",
            }
            
            # ä¸­æ–‡ç»“æ„ç±»å‹æ˜ å°„
            structure_mapping = {
                "æ æ†": "Railing",
                "ç“·ç –": "Tile",
                "åœ°å«": "Mat",
                "é—¨": "Door",
                "çª—": "Window",
                "å¢™å£": "Wall",
                "æŸ±å­": "Pillar",
                "å°é˜¶": "Step",
                "æ¥¼æ¢¯": "Stairs",
                "çª—æˆ·": "Window",
            }
            
            # åˆå¹¶æ‰€æœ‰æ˜ å°„
            all_mapping = {**room_mapping, **furniture_mapping, **structure_mapping}
            
            # é€ä¸ªæ›¿æ¢æ–‡æœ¬ä¸­çš„ä¸­æ–‡
            display_text = text
            for chinese, english in all_mapping.items():
                display_text = display_text.replace(chinese, english)
            
            # å¦‚æœå…¨æ˜¯ä¸­æ–‡ï¼Œå°è¯•æ›´é€šç”¨çš„æ›¿æ¢
            if any(ord(char) > 127 for char in display_text):
                # ä¿ç•™è‹±æ–‡éƒ¨åˆ†ï¼Œå…¶ä»–æ˜¾ç¤ºä¸ºç©º
                display_text = ''.join(char if ord(char) < 128 else '' for char in display_text)
            
            cv2.putText(img, display_text, pos, self.font, size, color, self.font_thickness)  
            return img  
        except Exception as e:  
            cv2.putText(img, "Status", pos, self.font, size, color, self.font_thickness)  
            return img  

    def display_loop(self):  
        """ğŸš€ä¼˜åŒ–ç‰ˆæ˜¾ç¤ºå¾ªç¯ - å¼‚æ­¥æ˜¾ç¤ºã€è‡ªé€‚åº”åˆ†è¾¨ç‡ã€æ€§èƒ½ç›‘æ§"""  
        window_name = self.config.get('visualization.window_name', "Hierarchical CLIP+SAM Semantic Mapping")  
        cv2.namedWindow(window_name, cv2.WINDOW_AUTOSIZE)  
        
        display_interval = 1.0 / 30.0  # ç›®æ ‡30 FPSæ˜¾ç¤º
        last_display_time = time.time()
        frame_count = 0
        
        while not rospy.is_shutdown() and self.running:  
            current_time = time.time()
            frame_time_start = current_time
            
            if self.latest_image is not None:  
                try:  
                    # ğŸš€ä¼˜åŒ–1: è‡ªé€‚åº”åˆ†è¾¨ç‡æ˜¾ç¤ºï¼ˆå‡å°‘æ˜¾å¡å‹åŠ›ï¼‰
                    display_img = self.image_resizer.adaptive_resize(
                        self.latest_image.copy(),
                        max_width=1280,
                        max_height=720
                    )
                    
                    # ä¸»è¦ä¿¡æ¯æ˜¾ç¤º  
                    main_text = f"Room: {self.current_room} (Conf: {self.current_confidence:.3f})"  
                    color = (0, 255, 0) if self.current_room != "æœªçŸ¥" else (0, 100, 255)  
                    display_img = self.draw_chinese_safe(display_img, main_text, (20, 50), color, 0.6)  
                    
                    # ç½®ä¿¡åº¦é˜ˆå€¼æ˜¾ç¤º  
                    threshold_text = f"Confidence Threshold: {self.confidence_threshold:.2f}"  
                    cv2.putText(display_img, threshold_text, (20, 80), self.font, 0.5, (255, 255, 0), 1)  
                    
                    # âœ¨ä¼˜åŒ–ï¼šå®¶å…·æ£€æµ‹æ˜¾ç¤ºï¼ˆåªæ˜¾ç¤ºæ–‡æœ¬ï¼Œé¿å…ç»˜åˆ¶æ©ç ï¼‰
                    if self.current_furniture:  
                        furniture_text = f"Furniture: {len(self.current_furniture)} detected"  
                        cv2.putText(display_img, furniture_text, (20, 110), self.font, 0.5, (139, 69, 19), 1)  
                        
                        # æ˜¾ç¤ºå‰3ä¸ªå®¶å…·  
                        furniture_list = list(self.current_furniture.keys())[:3]  
                        furniture_names = ", ".join(furniture_list)  
                        if len(furniture_names) > 40:  
                            furniture_names = furniture_names[:37] + "..."  
                        # ä½¿ç”¨ draw_chinese_safe å¤„ç†ä¸­æ–‡
                        display_img = self.draw_chinese_safe(display_img, furniture_names, (20, 130), (139, 69, 19), 0.4)
                    
                    # âœ¨ä¼˜åŒ–ï¼šç»“æ„æ£€æµ‹æ˜¾ç¤º - ä»…åœ¨Structureå¯ç”¨æ—¶æ˜¾ç¤º
                    structure_enabled = self.config.get('inference.structure_detection.enable', False)
                    if self.current_structures and structure_enabled:  
                        structure_text = f"Structures: {len(self.current_structures)} detected"  
                        cv2.putText(display_img, structure_text, (20, 155), self.font, 0.5, (105, 105, 105), 1)  
                        
                        # æ˜¾ç¤ºå‰3ä¸ªç»“æ„  
                        structure_list = list(self.current_structures.keys())[:3]  
                        structure_names = ", ".join(structure_list)  
                        if len(structure_names) > 40:  
                            structure_names = structure_names[:37] + "..."  
                        # ä½¿ç”¨ draw_chinese_safe å¤„ç†ä¸­æ–‡
                        display_img = self.draw_chinese_safe(display_img, structure_names, (20, 175), (105, 105, 105), 0.4)  
                    
                    # ç³»ç»ŸçŠ¶æ€æ˜¾ç¤º  
                    status = "Inferencing..." if self.is_inferencing else "Ready"  
                    status_color = (0, 255, 255) if self.is_inferencing else (255, 255, 255)  
                    cv2.putText(display_img, f"Status: {status}", (20, 200), self.font, 0.5, status_color, 1)  
                    
                    # ğŸš€ä¼˜åŒ–çš„ç»Ÿè®¡ä¿¡æ¯æ˜¾ç¤º
                    current_time = time.time()  
                    elapsed = current_time - self.start_time  
                    inference_fps = self.inference_count / elapsed if elapsed > 0 else 0
                    display_fps = self.fps_counter.get_fps()
                    
                    fps_text = f"Display: {display_fps:.1f} Hz | Inference: {inference_fps:.1f} Hz"  
                    cv2.putText(display_img, fps_text, (20, 225), self.font, 0.4, (0, 255, 0), 1)  
                    
                    success_rate = (self.successful_snapshots /   
                                  max(1, self.successful_snapshots + self.failed_snapshots)) * 100  
                    success_text = f"Success: {success_rate:.0f}% | Inferences: {self.inference_count}"  
                    cv2.putText(display_img, success_text, (20, 245), self.font, 0.4, (0, 255, 255), 1)  
                    
                    # åœ°å›¾ç”ŸæˆçŠ¶æ€  
                    if self.map_generation_completed:  
                        map_text = f"Maps: SAVED"  
                        map_color = (0, 255, 0)  
                    else:  
                        map_text = "Press 'm' for maps"  
                        map_color = (0, 255, 255)  
                    cv2.putText(display_img, map_text, (20, 265), self.font, 0.4, map_color, 1)  
                    
                    cv2.putText(display_img, "Optimized CLIP+SAM", (20, 285), self.font, 0.4, (255, 255, 0), 1)  
                    
                    # ğŸš€ä¼˜åŒ–2: é™åˆ¶æ˜¾ç¤ºå¸§ç‡ï¼ˆé˜²æ­¢å¡é¡¿ï¼‰
                    if current_time - last_display_time >= display_interval:
                        cv2.imshow(window_name, display_img)
                        self.fps_counter.tick()
                        last_display_time = current_time
                    
                    # ğŸš€ä¼˜åŒ–3: å®šæœŸå‘å¸ƒè¯­ä¹‰åœ°å›¾ï¼ˆå‡å°‘å‘å¸ƒé¢‘ç‡ï¼‰  
                    current_time = time.time()  
                    if current_time - self.last_map_publish_time >= self.map_publish_interval:  
                        self._publish_semantic_maps_optimized()  
                        self.last_map_publish_time = current_time  
                    
                    # è®°å½•å¸§å¤„ç†æ—¶é—´
                    frame_processing_time = time.time() - frame_time_start
                    self.system_monitor.record_frame_time(frame_processing_time)
                    
                    # å®šæœŸæ‰“å°è¯¦ç»†ç»Ÿè®¡  
                    if hasattr(self, '_last_detail_print'):  
                        if current_time - self._last_detail_print >= 10.0:  
                            self._print_detailed_stats()  
                            self._last_detail_print = current_time  
                    else:  
                        self._last_detail_print = current_time  
                        
                except Exception as e:  
                    print(f"æ˜¾ç¤ºé”™è¯¯: {e}")  
            
            # é”®ç›˜æ§åˆ¶  
            key = cv2.waitKey(1) & 0xFF  
            if key == ord('q'):  
                self.running = False  
                break  
            elif key == ord('m'):  
                if not self.map_generation_completed:  
                    print("ğŸ§ æ‰‹åŠ¨è§¦å‘å¤šå±‚æ¬¡è¯­ä¹‰åœ°å›¾ç”Ÿæˆ...")  
                    threading.Thread(target=self.generate_hierarchical_semantic_map, daemon=True).start()  
                else:  
                    print("âœ…å¤šå±‚æ¬¡åœ°å›¾å·²ç”Ÿæˆ")  
                    # é‡æ–°å‘å¸ƒè¯­ä¹‰åœ°å›¾  
                    self._publish_semantic_maps()  
                    
                    # æ˜¾ç¤ºä¿å­˜çš„æ–‡ä»¶  
                    for map_type, filename in self.saved_filenames.items():  
                        if filename:  
                            print(f"  ğŸ“{self._get_project_save_dir()}/{filename}")  
            elif key == ord('+') or key == ord('='):  
                self.confidence_threshold = min(0.95, self.confidence_threshold + 0.05)  
                print(f"ğŸ¯ç½®ä¿¡åº¦é˜ˆå€¼å¢åŠ : {self.confidence_threshold:.2f}")  
            elif key == ord('-') or key == ord('_'):  
                self.confidence_threshold = max(0.05, self.confidence_threshold - 0.05)  
                print(f"ğŸ¯ç½®ä¿¡åº¦é˜ˆå€¼é™ä½: {self.confidence_threshold:.2f}")  
            elif key == ord('r'):  
                # é‡ç½®æ‰€æœ‰è¯­ä¹‰ç½‘æ ¼  
                if self.semantic_grid is not None:  
                    self.semantic_grid.fill(0)  
                if self.furniture_grid is not None:  
                    self.furniture_grid.fill(0)  
                if self.structure_grid is not None:  
                    self.structure_grid.fill(0)  
                print("ğŸ§¹å¤šå±‚æ¬¡è¯­ä¹‰ç½‘æ ¼å·²é‡ç½®")  
            elif key == ord('s'):  
                print("ğŸ“Šå½“å‰ç³»ç»ŸçŠ¶æ€:")  
                self._print_detailed_stats()  
            elif key == ord('c'):
                total_coverage = sum(self.room_coverage.values())  
                print(f"ğŸ“æˆ¿é—´è¦†ç›–ç»Ÿè®¡(æ€»è®¡{total_coverage}åƒç´ ):")  
                for room, pixels in sorted(self.room_coverage.items()):  
                    percentage = (pixels / total_coverage) * 100 if total_coverage > 0 else 0  
                    print(f"  {room}: {pixels} åƒç´ ({percentage:.1f}%)")
            elif key == ord('w') or key == ord('W'):
                # æ‰‹åŠ¨ä¿å­˜å½“å‰åœ°å›¾åˆ° results/semantic_maps
                print("ğŸ’¾æ‰‹åŠ¨ä¿å­˜åœ°å›¾...")
                if self.latest_image is not None and self.current_room != "æœªçŸ¥":
                    try:
                        # åˆ›å»ºæ–°å¿«ç…§ç”¨äºä¿å­˜
                        snapshot = self.latest_image.copy()
                        
                        # è·å–ä¿å­˜ç›®å½•
                        save_dir = self._get_project_save_dir()
                        
                        # è·å–æ—¶é—´æˆ³å’Œæˆ¿é—´åç§°
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        room_names = self._get_detected_room_names()
                        
                        # ä¿å­˜å¤šç§æ ¼å¼çš„åœ°å›¾
                        if hasattr(self, 'current_snapshot_annotated') and self.current_snapshot_annotated is not None:
                            # ä¿å­˜æ ‡æ³¨ç‰ˆæœ¬ï¼ˆå¸¦æ ‡ç­¾ï¼‰
                            filename = f"manual_save_annotated_{timestamp}_{room_names}.png"
                            filepath = os.path.join(save_dir, filename)
                            cv2.imwrite(filepath, self.current_snapshot_annotated)
                            print(f"âœ…å·²ä¿å­˜æ ‡æ³¨åœ°å›¾: {filename}")
                        
                        # ä¿å­˜åŸå§‹ç‰ˆæœ¬
                        filename = f"manual_save_{timestamp}_{room_names}.png"
                        filepath = os.path.join(save_dir, filename)
                        cv2.imwrite(filepath, snapshot)
                        print(f"âœ…å·²ä¿å­˜åœ°å›¾: {filename}")
                        
                        # å¦‚æœæœ‰è¯­ä¹‰ç½‘æ ¼ï¼Œä¹Ÿä¿å­˜
                        if self.semantic_grid is not None:
                            # å½’ä¸€åŒ–å¹¶å¯è§†åŒ–è¯­ä¹‰ç½‘æ ¼
                            grid_vis = (self.semantic_grid.astype(np.float32) / 255.0 * 255).astype(np.uint8)
                            filename = f"manual_save_semantic_grid_{timestamp}_{room_names}.png"
                            filepath = os.path.join(save_dir, filename)
                            cv2.imwrite(filepath, grid_vis)
                            print(f"âœ…å·²ä¿å­˜è¯­ä¹‰ç½‘æ ¼: {filename}")
                        
                        print(f"ğŸ“ä¿å­˜ä½ç½®: {save_dir}")
                    except Exception as e:
                        print(f"âŒä¿å­˜å¤±è´¥: {e}")
                else:
                    print("âš ï¸æ— æ³•ä¿å­˜: æœªæ£€æµ‹åˆ°æˆ¿é—´æˆ–æ— å›¾åƒæ•°æ®")
        
        cv2.destroyAllWindows()  
        rospy.signal_shutdown("Display window closed")  

    def _print_detailed_stats(self):  
        """æ‰“å°è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""  
        try:  
            current_time = time.time()  
            elapsed = current_time - self.start_time  
            success_rate = (self.successful_snapshots /   
                          max(1, self.successful_snapshots + self.failed_snapshots)) * 100  
            
            print(f"ğŸ“Šå¤šå±‚æ¬¡æ¨ç†#{self.inference_count}:{self.current_room} | "  
                  f"ç½®ä¿¡åº¦:{self.current_confidence:.3f} | æˆåŠŸç‡:{success_rate:.1f}%")  
            
            if self.current_furniture:  
                furniture_summary = {name: info['confidence']   
                                   for name, info in self.current_furniture.items()}  
                print(f"  ğŸª‘å½“å‰å®¶å…·: {furniture_summary}")  
            
            if self.current_structures:  
                structure_summary = {name: info['confidence']   
                                   for name, info in self.current_structures.items()}  
                print(f"  ğŸ§±å½“å‰ç»“æ„: {structure_summary}")  
                
        except Exception as e:  
            pass  

    # ==== åœ°å›¾ç”Ÿæˆå’Œä¿å­˜ ====  

    def generate_hierarchical_semantic_map(self):  
        """ğŸ§ ç”Ÿæˆå¤šå±‚æ¬¡è¯­ä¹‰åœ°å›¾"""  
        try:  
            if self.semantic_grid is None or self.occupancy_map is None:  
                print("âŒåœ°å›¾æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆè¯­ä¹‰åœ°å›¾")  
                return False  
            
            print("ğŸ§ å¼€å§‹ç”Ÿæˆå¤šå±‚æ¬¡è¯­ä¹‰åœ°å›¾...")  
            
            height, width = self.semantic_grid.shape  
            occupancy_data = np.array(self.occupancy_map.data).reshape((height, width))  
            
            # 1. ç”Ÿæˆæˆ¿é—´å±‚è¯­ä¹‰åœ°å›¾  
            success = self.generate_intelligent_semantic_map()  
            if not success:  
                return False  
            
            # 2. ç”Ÿæˆå®¶å…·å±‚åœ°å›¾  
            self._generate_furniture_map(occupancy_data)  
            
            # 3. ç”Ÿæˆç»“æ„å±‚åœ°å›¾ - ä»…åœ¨å¯ç”¨æ—¶ç”Ÿæˆ
            structure_enabled = self.config.get('inference.structure_detection.enable', False)
            if structure_enabled:
                self._generate_structure_map(occupancy_data)
            else:
                print("  â­ï¸ è·³è¿‡ç»“æ„åœ°å›¾ç”Ÿæˆï¼ˆå·²ç¦ç”¨ï¼‰")
            
            # 4. ç”Ÿæˆç»„åˆåœ°å›¾  
            self._generate_combined_map(occupancy_data)  
            
            # 5. ä¿å­˜æ‰€æœ‰åœ°å›¾  
            self._save_all_hierarchical_maps()  
            
            # 6. å‘å¸ƒåˆ°RViz  
            self._publish_semantic_maps()  
            
            self.map_generation_completed = True  
            print("ğŸ¨å¤šå±‚æ¬¡è¯­ä¹‰åœ°å›¾ç”Ÿæˆå®Œæˆï¼")  
            return True  
            
        except Exception as e:  
            print(f"âŒå¤šå±‚æ¬¡åœ°å›¾ç”Ÿæˆé”™è¯¯: {e}")  
            return False  

    def generate_intelligent_semantic_map(self):  
        """ç”Ÿæˆæ™ºèƒ½è¯­ä¹‰åœ°å›¾ - æˆ¿é—´å±‚"""  
        try:  
            if self.semantic_grid is None or self.occupancy_map is None:  
                print("âŒåœ°å›¾æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆè¯­ä¹‰åœ°å›¾")  
                return False  
            
            print("ğŸ§ æ™ºèƒ½è¯­ä¹‰åœ°å›¾ç”Ÿæˆä¸­...")  
            
            height, width = self.semantic_grid.shape  
            occupancy_data = np.array(self.occupancy_map.data).reshape((height, width))  
            
            # åˆ›å»ºå½©è‰²åœ°å›¾  
            color_map = np.zeros((height, width, 3), dtype=np.uint8)  
            
            # æœªçŸ¥åŒºåŸŸ - ç°è‰²  
            unknown_mask = (occupancy_data == -1)  
            color_map[unknown_mask] = [128, 128, 128]  
            
            # è‡ªç”±åŒºåŸŸ - æµ…ç°è‰²  
            free_mask = (occupancy_data == 0)  
            color_map[free_mask] = [240, 240, 240]  
            
            # éšœç¢ç‰© - é»‘è‰²  
            obstacle_mask = (occupancy_data == 100)  
            color_map[obstacle_mask] = [0, 0, 0]  
            
            # å½¢æ€å­¦å¤„ç†  
            kernel_size = 3  
            kernel = np.ones((kernel_size, kernel_size), np.uint8)  
            
            # å¤„ç†æ¯ä¸ªæˆ¿é—´  
            unique_codes = np.unique(self.semantic_grid)  
            room_regions = {}  
            
            for room_code in unique_codes:  
                if room_code == 0:  # è·³è¿‡èƒŒæ™¯  
                    continue  
                
                # æŸ¥æ‰¾å¯¹åº”çš„æˆ¿é—´åç§°  
                room_name = None  
                for name, code in self.room_codes.items():  
                    if code == room_code:  
                        room_name = name  
                        break  
                
                if room_name is None:  
                    continue  
                
                # æå–æˆ¿é—´åŒºåŸŸ  
                room_mask = (self.semantic_grid == room_code)  
                
                # å½¢æ€å­¦å¤„ç†  
                room_mask_processed = cv2.morphologyEx(  
                    room_mask.astype(np.uint8), cv2.MORPH_CLOSE, kernel)  
                room_mask_processed = cv2.morphologyEx(  
                    room_mask_processed, cv2.MORPH_OPEN, kernel)  
                
                # åªåœ¨è‡ªç”±ç©ºé—´æ ‡æ³¨  
                final_mask = room_mask_processed.astype(bool) & free_mask  
                
                if np.sum(final_mask) > 0:  
                    room_color = self.room_colors.get(room_name, [255, 255, 255])  
                    color_map[final_mask] = room_color  
                    
                    room_regions[room_name] = {  
                        'pixels': np.sum(final_mask),  
                        'color': room_color  
                    }  
                    
                    print(f"  ğŸ {room_name}: {np.sum(final_mask)} åƒç´ ")  
            
            # ä¿å­˜æˆ¿é—´è¯­ä¹‰åœ°å›¾  
            self.semantic_map_image = color_map  
            
            # è®¡ç®—åŒºåŸŸä¸­å¿ƒ  
            self.region_centers = self._calculate_region_centers(room_regions)  
            
            # ç”Ÿæˆå¸¦æ ‡æ³¨çš„åœ°å›¾  
            self._generate_annotated_map(color_map, room_regions)  
            
            print(f"âœ…æ™ºèƒ½è¯­ä¹‰åœ°å›¾ç”ŸæˆæˆåŠŸï¼ŒåŒ…å«{len(room_regions)} ä¸ªæˆ¿é—´åŒºåŸŸ")  
            return True  
            
        except Exception as e:  
            print(f"âŒæ™ºèƒ½è¯­ä¹‰åœ°å›¾ç”Ÿæˆå¤±è´¥: {e}")  
            return False  

    def _generate_furniture_map(self, occupancy_data):  
        """ç”Ÿæˆå®¶å…·è¯­ä¹‰åœ°å›¾"""  
        try:  
            if self.furniture_grid is None:  
                return  
            
            height, width = self.furniture_grid.shape  
            color_map = np.zeros((height, width, 3), dtype=np.uint8)  
            
            # è®¾ç½®èƒŒæ™¯  
            unknown_mask = (occupancy_data == -1)  
            color_map[unknown_mask] = [128, 128, 128]  
            
            free_mask = (occupancy_data == 0)  
            color_map[free_mask] = [240, 240, 240]  
            
            obstacle_mask = (occupancy_data == 100)  
            color_map[obstacle_mask] = [0, 0, 0]  
            
            # æ ‡æ³¨å®¶å…·  
            for category, items in self.furniture_config.items():  
                if 'codes' not in items or 'colors' not in items:  
                    continue  
                
                for furniture_name, furniture_code in items['codes'].items():  
                    furniture_mask = (self.furniture_grid == furniture_code)  
                    if np.any(furniture_mask):  
                        color = items['colors'][furniture_name]  
                        color_map[furniture_mask] = color  
                        print(f"  ğŸª‘{furniture_name}: {np.sum(furniture_mask)} åƒç´ ")  
            
            self.furniture_map_image = color_map  
            
        except Exception as e:  
            print(f"âŒå®¶å…·åœ°å›¾ç”Ÿæˆé”™è¯¯: {e}")  

    def _generate_structure_map(self, occupancy_data):  
        """ç”Ÿæˆç»“æ„è¯­ä¹‰åœ°å›¾"""  
        try:  
            if self.structure_grid is None:  
                return  
            
            height, width = self.structure_grid.shape  
            color_map = np.zeros((height, width, 3), dtype=np.uint8)  
            
            # è®¾ç½®èƒŒæ™¯  
            unknown_mask = (occupancy_data == -1)  
            color_map[unknown_mask] = [128, 128, 128]  
            
            free_mask = (occupancy_data == 0)  
            color_map[free_mask] = [240, 240, 240]  
            
            obstacle_mask = (occupancy_data == 100)  
            color_map[obstacle_mask] = [0, 0, 0]  
            
            # æ ‡æ³¨ç»“æ„  
            for category, items in self.structure_config.items():  
                if 'codes' not in items or 'colors' not in items:  
                    continue  
                
                for structure_name, structure_code in items['codes'].items():  
                    structure_mask = (self.structure_grid == structure_code)  
                    if np.any(structure_mask):  
                        color = items['colors'][structure_name]  
                        color_map[structure_mask] = color  
                        print(f"  ğŸ§±{structure_name}: {np.sum(structure_mask)} åƒç´ ")  
            
            self.structure_map_image = color_map  
            
        except Exception as e:  
            print(f"âŒç»“æ„åœ°å›¾ç”Ÿæˆé”™è¯¯: {e}")  

    def _generate_combined_map(self, occupancy_data):  
        """ç”Ÿæˆç»„åˆè¯­ä¹‰åœ°å›¾"""  
        try:  
            height, width = occupancy_data.shape  
            combined_map = np.zeros((height, width, 3), dtype=np.uint8)  
            
            # è®¾ç½®èƒŒæ™¯  
            unknown_mask = (occupancy_data == -1)  
            combined_map[unknown_mask] = [128, 128, 128]  
            
            free_mask = (occupancy_data == 0)  
            combined_map[free_mask] = [240, 240, 240]  
            
            obstacle_mask = (occupancy_data == 100)  
            combined_map[obstacle_mask] = [0, 0, 0]  
            
            # å åŠ æˆ¿é—´å±‚ï¼ˆåº•å±‚ï¼‰  
            if self.semantic_map_image is not None:  
                room_mask = np.any(self.semantic_map_image != [240, 240, 240], axis=2)  
                combined_map[room_mask] = self.semantic_map_image[room_mask]  
            
            # å åŠ å®¶å…·å±‚ï¼ˆä¸­å±‚ï¼ŒåŠé€æ˜ï¼‰  
            if self.furniture_map_image is not None:  
                furniture_mask = np.any(self.furniture_map_image != [240, 240, 240], axis=2)  
                alpha = 0.7  # é€æ˜åº¦  
                combined_map[furniture_mask] = (  
                    alpha * self.furniture_map_image[furniture_mask] +   
                    (1 - alpha) * combined_map[furniture_mask]  
                ).astype(np.uint8)  
            
            # å åŠ ç»“æ„å±‚ï¼ˆé¡¶å±‚ï¼‰  
            if self.structure_map_image is not None:  
                structure_mask = np.any(self.structure_map_image != [240, 240, 240], axis=2)  
                combined_map[structure_mask] = self.structure_map_image[structure_mask]  
            
            self.combined_map_image = combined_map  
            print("  ğŸ¨ç»„åˆåœ°å›¾ç”Ÿæˆå®Œæˆ")  
            
        except Exception as e:  
            print(f"âŒç»„åˆåœ°å›¾ç”Ÿæˆé”™è¯¯: {e}")  

    def _generate_annotated_map(self, color_map, room_regions):  
        """ç”Ÿæˆå¸¦æ–‡å­—æ ‡æ³¨çš„åœ°å›¾"""  
        try:  
            annotated_map = color_map.copy()  
            
            font_scale, font_thickness = 0.6, 1  
            font = cv2.FONT_HERSHEY_SIMPLEX  
            
            for room_name, region_info in room_regions.items():  
                if room_name in self.region_centers:  
                    center = self.region_centers[room_name]  
                    
                    # ä¸­æ–‡åˆ°è‹±æ–‡æ˜ å°„  
                    english_mapping = {  
                        "å®¢å…": "Living Room",  
                        "å§å®¤": "Bedroom",  
                        "å¨æˆ¿": "Kitchen",   
                        "å«ç”Ÿé—´": "Bathroom",  
                        "é˜³å°": "Balcony",  
                        "ä¹¦æˆ¿": "Study",  
                        "é¤å…": "Dining Room",  
                        "ç„å…³": "Entrance"  
                    }  
                    
                    display_text = english_mapping.get(room_name, room_name)  
                    
                    # è®¡ç®—æ–‡å­—å¤§å°  
                    (text_width, text_height), baseline = cv2.getTextSize(  
                        display_text, font, font_scale, font_thickness)  
                    
                    # ç»˜åˆ¶èƒŒæ™¯æ¡†  
                    bg_start = (center[0] - text_width // 2 - 10, center[1] - text_height // 2 - 10)  
                    bg_end = (center[0] + text_width // 2 + 10, center[1] + text_height // 2 + 10)  
                    cv2.rectangle(annotated_map, bg_start, bg_end, (0, 0, 0), -1)  
                    cv2.rectangle(annotated_map, bg_start, bg_end, (255, 255, 255), 2)  
                    
                    # ç»˜åˆ¶æ–‡å­—  
                    text_pos = (center[0] - text_width // 2, center[1] + text_height // 2)  
                    cv2.putText(annotated_map, display_text, text_pos, font,   
                              font_scale, (255, 255, 255), font_thickness)  
            
            self.annotated_semantic_map_image = annotated_map  
            
        except Exception as e:  
            print(f"âŒæ ‡æ³¨åœ°å›¾ç”Ÿæˆé”™è¯¯: {e}")  

    def _publish_semantic_maps(self):  
        """å‘å¸ƒè¯­ä¹‰åœ°å›¾åˆ°RViz"""  
        try:  
            # âœ¨å…³é”®ä¿®å¤ï¼šå‘å¸ƒè¯­ä¹‰å ç”¨æ …æ ¼ï¼ˆè¿™æ˜¯RVizæ˜¾ç¤ºå¤šè¾¹å½¢åœ°å›¾çš„æ–¹å¼ï¼‰
            self._publish_semantic_occupancy_grid()
            
            # å‘å¸ƒæˆ¿é—´è¯­ä¹‰åœ°å›¾  
            if self.semantic_map_image is not None:  
                semantic_msg = self.bridge.cv2_to_imgmsg(  
                    cv2.cvtColor(self.semantic_map_image, cv2.COLOR_RGB2BGR), "bgr8")  
                semantic_msg.header.stamp = rospy.Time.now()  
                semantic_msg.header.frame_id = "map"  
                self.semantic_image_pub.publish(semantic_msg)  
            
            # å‘å¸ƒå®¶å…·åœ°å›¾  
            if self.furniture_map_image is not None:  
                furniture_msg = self.bridge.cv2_to_imgmsg(  
                    cv2.cvtColor(self.furniture_map_image, cv2.COLOR_RGB2BGR), "bgr8")  
                furniture_msg.header.stamp = rospy.Time.now()
                furniture_msg.header.frame_id = "map"
                self.furniture_map_pub.publish(furniture_msg)
            
            # å‘å¸ƒç»“æ„åœ°å›¾
            if self.structure_map_image is not None:
                structure_msg = self.bridge.cv2_to_imgmsg(
                    cv2.cvtColor(self.structure_map_image, cv2.COLOR_RGB2BGR), "bgr8")
                structure_msg.header.stamp = rospy.Time.now()
                structure_msg.header.frame_id = "map"
                self.structure_map_pub.publish(structure_msg)
                
        except Exception as e:
            rospy.logwarn(f"è¯­ä¹‰åœ°å›¾å‘å¸ƒé”™è¯¯: {e}")

    def _publish_semantic_maps_optimized(self):
        """ğŸš€ä¼˜åŒ–ç‰ˆåœ°å›¾å‘å¸ƒ - é™ä½å‘å¸ƒé¢‘ç‡ï¼Œåªå‘å¸ƒå˜åŒ–çš„åœ°å›¾"""
        try:
            # âœ¨å…³é”®ä¿®å¤ï¼šæ— æ¡ä»¶å‘å¸ƒè¯­ä¹‰å ç”¨æ …æ ¼ï¼ˆè¿™æ˜¯RVizèƒ½çœ‹åˆ°çš„å…³é”®æ¶ˆæ¯ï¼‰
            self._publish_semantic_occupancy_grid()
            
            # åªåœ¨æœ‰é‡è¦å˜åŒ–æ—¶å‘å¸ƒå›¾åƒï¼Œå‡å°‘ç½‘ç»œè´Ÿè½½
            if self.map_update_optimizer.has_significant_changes(self.semantic_grid):
                # å‘å¸ƒæˆ¿é—´è¯­ä¹‰åœ°å›¾
                if self.semantic_map_image is not None:
                    try:
                        # å‹ç¼©å›¾åƒä»¥å‡å°‘å¸¦å®½
                        compressed_img = cv2.resize(
                            self.semantic_map_image,
                            None,
                            fx=0.5, fy=0.5,
                            interpolation=cv2.INTER_AREA
                        )
                        semantic_msg = self.bridge.cv2_to_imgmsg(
                            cv2.cvtColor(compressed_img, cv2.COLOR_RGB2BGR), "bgr8")
                        semantic_msg.header.stamp = rospy.Time.now()
                        semantic_msg.header.frame_id = "map"
                        self.semantic_image_pub.publish(semantic_msg)
                    except Exception as e:
                        rospy.logwarn(f"æˆ¿é—´åœ°å›¾å‘å¸ƒå¤±è´¥: {e}")
                
                # å‘å¸ƒå®¶å…·åœ°å›¾
                if self.furniture_map_image is not None:
                    try:
                        compressed_img = cv2.resize(
                            self.furniture_map_image,
                            None,
                            fx=0.5, fy=0.5,
                            interpolation=cv2.INTER_AREA
                        )
                        furniture_msg = self.bridge.cv2_to_imgmsg(
                            cv2.cvtColor(compressed_img, cv2.COLOR_RGB2BGR), "bgr8")
                        furniture_msg.header.stamp = rospy.Time.now()
                        furniture_msg.header.frame_id = "map"
                        self.furniture_map_pub.publish(furniture_msg)
                    except Exception as e:
                        rospy.logwarn(f"å®¶å…·åœ°å›¾å‘å¸ƒå¤±è´¥: {e}")
                
                # å‘å¸ƒç»“æ„åœ°å›¾
                if self.structure_map_image is not None:
                    try:
                        compressed_img = cv2.resize(
                            self.structure_map_image,
                            None,
                            fx=0.5, fy=0.5,
                            interpolation=cv2.INTER_AREA
                        )
                        structure_msg = self.bridge.cv2_to_imgmsg(
                            cv2.cvtColor(compressed_img, cv2.COLOR_RGB2BGR), "bgr8")
                        structure_msg.header.stamp = rospy.Time.now()
                        structure_msg.header.frame_id = "map"
                        self.structure_map_pub.publish(structure_msg)
                    except Exception as e:
                        rospy.logwarn(f"ç»“æ„åœ°å›¾å‘å¸ƒå¤±è´¥: {e}")
                
        except Exception as e:
            rospy.logwarn(f"ä¼˜åŒ–ç‰ˆåœ°å›¾å‘å¸ƒé”™è¯¯: {e}")

    def _calculate_region_centers(self, room_regions):
        """è®¡ç®—æˆ¿é—´åŒºåŸŸä¸­å¿ƒç‚¹"""
        region_centers = {}
        try:
            for room_name in room_regions.keys():
                room_code = self.room_codes.get(room_name)
                if room_code is None:
                    continue
                
                # æ‰¾åˆ°æˆ¿é—´åŒºåŸŸ
                room_mask = (self.semantic_grid == room_code)
                if not np.any(room_mask):
                    continue
                
                # è¿é€šç»„ä»¶åˆ†æï¼Œæ‰¾åˆ°æœ€å¤§åŒºåŸŸ
                labeled_array, num_features = ndimage.label(room_mask)
                if num_features == 0:
                    continue
                
                # æ‰¾åˆ°æœ€å¤§è¿é€šç»„ä»¶
                component_sizes = ndimage.sum(room_mask, labeled_array, range(1, num_features + 1))
                largest_component = np.argmax(component_sizes) + 1
                largest_mask = (labeled_array == largest_component)
                
                # è®¡ç®—ä¸­å¿ƒ
                center_of_mass = ndimage.center_of_mass(largest_mask)
                center_y, center_x = int(center_of_mass[0]), int(center_of_mass[1])
                
                region_centers[room_name] = (center_x, center_y)
                
        except Exception as e:
            print(f"âŒåŒºåŸŸä¸­å¿ƒè®¡ç®—é”™è¯¯: {e}")
        
        return region_centers

    def _save_all_hierarchical_maps(self):
        """ä¿å­˜æ‰€æœ‰å¤šå±‚æ¬¡è¯­ä¹‰åœ°å›¾"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            base_save_dir = self._get_project_save_dir()
            # ğŸ“ åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„å­æ–‡ä»¶å¤¹æ¥ç»„ç»‡åœ°å›¾
            save_dir = os.path.join(base_save_dir, f"map_{timestamp}")
            os.makedirs(save_dir, exist_ok=True)
            
            detected_rooms = self._get_detected_room_names()
            
            # âœ¨ä¿å­˜å®¶å…·åœ°å›¾
            if self.furniture_map_image is not None:
                furniture_filename = f"clip_sam_furniture_{timestamp}_{detected_rooms}.png"
                furniture_path = os.path.join(save_dir, furniture_filename)
                furniture_bgr = cv2.cvtColor(self.furniture_map_image, cv2.COLOR_RGB2BGR)
                cv2.imwrite(furniture_path, furniture_bgr)
                self.saved_filenames['furniture'] = furniture_filename
            
            # âœ¨ä¿å­˜ç»“æ„åœ°å›¾
            if self.structure_map_image is not None:
                structure_filename = f"clip_sam_structure_{timestamp}_{detected_rooms}.png"
                structure_path = os.path.join(save_dir, structure_filename)
                structure_bgr = cv2.cvtColor(self.structure_map_image, cv2.COLOR_RGB2BGR)
                cv2.imwrite(structure_path, structure_bgr)
                self.saved_filenames['structure'] = structure_filename
            
            # âœ¨ä¿å­˜ç»„åˆåœ°å›¾
            if self.combined_map_image is not None:
                combined_filename = f"clip_sam_combined_{timestamp}_{detected_rooms}.png"
                combined_path = os.path.join(save_dir, combined_filename)
                combined_bgr = cv2.cvtColor(self.combined_map_image, cv2.COLOR_RGB2BGR)
                cv2.imwrite(combined_path, combined_bgr)
                self.saved_filenames['combined'] = combined_filename
            
            # ä¿å­˜æˆ¿é—´å±‚ç›¸å…³åœ°å›¾
            self._save_original_maps(timestamp, detected_rooms)
            
            # ğŸ“Œ æ–°å¢ï¼šç”Ÿæˆèˆªç‚¹å¯¼èˆªæ–‡ä»¶ï¼ˆPGMã€YAMLã€XMLï¼‰
            self._generate_waypoint_files(timestamp, detected_rooms)
            
            print(f"ğŸ’¾å¤šå±‚æ¬¡åœ°å›¾ä¿å­˜å®Œæˆ:")
            print(f"  ğŸ“ä¿å­˜ç›®å½•: {save_dir}")
            for map_type, filename in self.saved_filenames.items():
                if filename:
                    print(f"  ğŸ“„{filename}")
                    
        except Exception as e:
            print(f"âŒå¤šå±‚æ¬¡åœ°å›¾ä¿å­˜é”™è¯¯: {e}")

    def _save_original_maps(self, timestamp, detected_rooms):
        """ä¿å­˜åŸæœ‰çš„æˆ¿é—´åœ°å›¾"""
        try:
            base_save_dir = self._get_project_save_dir()
            # ğŸ“ ä½¿ç”¨ä¸ _save_all_hierarchical_maps ç›¸åŒçš„æ—¶é—´æˆ³å­æ–‡ä»¶å¤¹
            save_dir = os.path.join(base_save_dir, f"map_{timestamp}")
            os.makedirs(save_dir, exist_ok=True)
            
            # ä¿å­˜åŸºç¡€è¯­ä¹‰åœ°å›¾
            if self.semantic_map_image is not None:
                original_filename = f"clip_sam_semantic_{timestamp}_{detected_rooms}.png"
                original_path = os.path.join(save_dir, original_filename)
                original_bgr = cv2.cvtColor(self.semantic_map_image, cv2.COLOR_RGB2BGR)
                cv2.imwrite(original_path, original_bgr)
                self.saved_filenames['original'] = original_filename
            
            # ä¿å­˜æ™ºèƒ½è¯­ä¹‰åœ°å›¾ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if hasattr(self, 'raw_semantic_map_image') and self.raw_semantic_map_image is not None:
                intelligent_filename = f"clip_sam_intelligent_{timestamp}_{detected_rooms}.png"
                intelligent_path = os.path.join(save_dir, intelligent_filename)
                intelligent_bgr = cv2.cvtColor(self.raw_semantic_map_image, cv2.COLOR_RGB2BGR)
                cv2.imwrite(intelligent_path, intelligent_bgr)
                self.saved_filenames['intelligent'] = intelligent_filename
            
            # ä¿å­˜å¸¦æ ‡æ³¨çš„åœ°å›¾
            if self.annotated_semantic_map_image is not None:
                annotated_filename = f"clip_sam_annotated_{timestamp}_{detected_rooms}.png"
                annotated_path = os.path.join(save_dir, annotated_filename)
                annotated_bgr = cv2.cvtColor(self.annotated_semantic_map_image, cv2.COLOR_RGB2BGR)
                cv2.imwrite(annotated_path, annotated_bgr)
                self.saved_filenames['annotated'] = annotated_filename
                
        except Exception as e:
            print(f"âŒåŸæœ‰åœ°å›¾ä¿å­˜é”™è¯¯: {e}")

    def _get_project_save_dir(self):
        """è·å–é¡¹ç›®ä¿å­˜ç›®å½• - ä½¿ç”¨è·¯å¾„ç®¡ç†å™¨è·å–å¯ç§»æ¤çš„è·¯å¾„"""
        try:
            # ä½¿ç”¨è·¯å¾„ç®¡ç†å™¨è·å–è¯­ä¹‰åœ°å›¾ç›®å½•
            config_save_dir = self.config.get('map_save.directory', None)
            if config_save_dir and config_save_dir.startswith('/'):
                # å¦‚æœé…ç½®ä¸­æœ‰ç»å¯¹è·¯å¾„ï¼Œå°è¯•ä½¿ç”¨å®ƒ
                os.makedirs(config_save_dir, exist_ok=True)
                # æµ‹è¯•å†™å…¥æƒé™
                test_file = os.path.join(config_save_dir, ".write_test")
                try:
                    with open(test_file, "w") as f:
                        f.write("test")
                    os.remove(test_file)
                    print(f"âœ…ä½¿ç”¨é…ç½®ç›®å½•: {config_save_dir}")
                    return config_save_dir
                except:
                    pass  # æƒé™ä¸è¶³ï¼Œä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ
            
            # ä½¿ç”¨è·¯å¾„ç®¡ç†å™¨è·å–å¯ç§»æ¤çš„ç›®å½•
            project_dir = self.path_manager.get_semantic_maps_dir()
            print(f"âœ…ä½¿ç”¨åŒ…ç›¸å¯¹ç›®å½•: {project_dir}")
            return project_dir
            
        except Exception as e:
            print(f"âŒä¿å­˜ç›®å½•è·å–å¤±è´¥: {e}")
            # æœ€åå¤‡é€‰ï¼šä½¿ç”¨ä¸´æ—¶ç›®å½•
            fallback_dir = self.path_manager.get_temp_dir()
            print(f"âš ï¸ä½¿ç”¨ä¸´æ—¶ç›®å½•: {fallback_dir}")
            return fallback_dir

    def _get_detected_room_names(self):
        """è·å–æ£€æµ‹åˆ°çš„æˆ¿é—´åç§°å­—ç¬¦ä¸²"""
        try:
            if not self.room_coverage:
                return "empty"
            
            room_names = "_".join(sorted(self.room_coverage.keys()))
            # é™åˆ¶é•¿åº¦
            if len(room_names) > 50:
                room_names = room_names[:47] + "..."
            
            return room_names.replace(" ", "_")
        except:
            return "unknown"

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        print("ğŸ§¹æ¸…ç†èµ„æºä¸­...")
        self.running = False
        
        try:
            import shutil
            if os.path.exists(self.temp_dir):
                shutil.rmtree(self.temp_dir)
        except:
            pass
        
        print("âœ…èµ„æºæ¸…ç†å®Œæˆ")

    def _generate_waypoint_files(self, timestamp, detected_rooms):
        """
        ğŸŒŸ æ–°å¢ï¼šç”Ÿæˆèˆªç‚¹å¯¼èˆªæ–‡ä»¶ï¼ˆPGMã€YAMLã€XMLï¼‰
        
        Args:
            timestamp: æ—¶é—´æˆ³
            detected_rooms: æ£€æµ‹åˆ°çš„æˆ¿é—´åç§°
        """
        try:
            # 1. åˆ›å»ºèˆªç‚¹æ–‡ä»¶å¤¹ - ä½¿ç”¨è·¯å¾„ç®¡ç†å™¨
            waypoints_save_dir = os.path.join(
                self.path_manager.get_waypoints_dir(),
                f"map_{timestamp}"
            )
            os.makedirs(waypoints_save_dir, exist_ok=True)
            
            # 2. å‡†å¤‡æ•°æ®
            if self.occupancy_map is None or self.semantic_grid is None:
                print("  âš ï¸ èˆªç‚¹æ–‡ä»¶ç”Ÿæˆï¼šç¼ºå°‘å¿…è¦çš„åœ°å›¾æ•°æ®")
                return
            
            # è½¬æ¢å ç”¨æ …æ ¼æ•°æ®
            occupancy_data = np.array(self.occupancy_map.data).reshape(
                (self.occupancy_map.info.height, self.occupancy_map.info.width)
            )
            
            # æ„å»ºåœ°å›¾å…ƒæ•°æ®
            map_metadata = {
                'resolution': self.occupancy_map.info.resolution,
                'origin': [
                    self.occupancy_map.info.origin.position.x,
                    self.occupancy_map.info.origin.position.y,
                    self.occupancy_map.info.origin.position.z
                ]
            }
            
            # 3. åˆ›å»ºèˆªç‚¹ç”Ÿæˆå™¨å¹¶ç”Ÿæˆæ–‡ä»¶
            generator = WaypointGenerator(waypoints_save_dir)
            results = generator.generate_all_files(
                occupancy_data,
                map_metadata,
                self.region_centers,
                self.semantic_grid,
                detected_rooms
            )
            
            # 4. æ‰“å°ç”Ÿæˆç»“æœ
            if results['success']:
                print(f"\nğŸ¯èˆªç‚¹å¯¼èˆªæ–‡ä»¶ç”ŸæˆæˆåŠŸ:")
                print(f"  ğŸ“ä¿å­˜ç›®å½•: {waypoints_save_dir}")
                if results['pgm']:
                    print(f"  ğŸ“„PGM æ …æ ¼åœ°å›¾: {results['pgm']}")
                if results['yaml']:
                    print(f"  ğŸ“„YAML å…ƒæ•°æ®: {results['yaml']}")
                if results['xml']:
                    print(f"  ğŸ“„XML èˆªç‚¹æ–‡ä»¶: {results['xml']}")
                    print(f"     èˆªç‚¹æ•°é‡: {len(self.region_centers)}")
                    for room_name, center in sorted(self.region_centers.items()):
                        print(f"     - {room_name}: ({center[0]:.2f}, {center[1]:.2f})")
            else:
                print(f"  âš ï¸ èˆªç‚¹å¯¼èˆªæ–‡ä»¶ç”Ÿæˆéƒ¨åˆ†å¤±è´¥")
                if results['errors']:
                    for error in results['errors']:
                        print(f"     é”™è¯¯: {error}")
            
        except Exception as e:
            print(f"  âŒèˆªç‚¹æ–‡ä»¶ç”Ÿæˆé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()


def main():
    """ä¸»å‡½æ•°"""
    try:
        rospy.init_node('hierarchical_clip_sam_semantic_mapper', anonymous=True)
        
        # ğŸ“Œ ä½¿ç”¨è·¯å¾„ç®¡ç†å™¨è·å–é…ç½®æ–‡ä»¶è·¯å¾„ - æ”¯æŒå¤šç§è·¯å¾„æ–¹å¼
        from utils.path_manager import get_path_manager
        path_manager = get_path_manager()
        path_manager.print_structure()
        
        # è·å–é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒå‚æ•°è¦†ç›–ï¼‰
        config_path = rospy.get_param('~config_path', None)
        if config_path is None:
            config_path = path_manager.get_config_file('clip_sam_config.yaml')
        
        # åˆ›å»ºå¤šå±‚æ¬¡è¯­ä¹‰å»ºå›¾å™¨
        mapper = HierarchicalCLIPSAMMapping(config_path)
        
        # åˆå§‹åŒ–ROS
        mapper.initialize_ros()
        
        print("ğŸš€å¤šå±‚æ¬¡CLIP+SAMè¯­ä¹‰å»ºå›¾ç³»ç»Ÿå¯åŠ¨æˆåŠŸ")
        print()
        print("ğŸ“‹æ“ä½œæŒ‡å—:")
        print("  ğŸ¯ +/-  : è°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼")
        print("  ğŸ—ºï¸  m   : ç”Ÿæˆå¤šå±‚æ¬¡è¯­ä¹‰åœ°å›¾")
        print("  ğŸ§¹  r   : é‡ç½®è¯­ä¹‰ç½‘æ ¼")
        print("  ğŸ“Š  s   : æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€")
        print("  ğŸ“  c   : æ˜¾ç¤ºæˆ¿é—´è¦†ç›–ç»Ÿè®¡")
        print("  âŒ  q   : é€€å‡ºç³»ç»Ÿ")
        print()
        print("ğŸ¨ç³»ç»Ÿç‰¹æ€§:")
        print("  ğŸ  CLIPæˆ¿é—´ç±»å‹è¯†åˆ«")
        print("  ğŸª‘ å®¶å…·ç‰©å“æ£€æµ‹ä¸åˆ†å‰²")
        print("  ğŸ§± å»ºç­‘ç»“æ„å…ƒç´ è¯†åˆ«")
        print("  ğŸ—ºï¸ å¤šå±‚æ¬¡è¯­ä¹‰åœ°å›¾ç”Ÿæˆ")
        print("  ğŸ¯ å®æ—¶ç½®ä¿¡åº¦é˜ˆå€¼è°ƒæ•´")
        print()
        
        # å¯åŠ¨æ˜¾ç¤ºçº¿ç¨‹
        display_thread = threading.Thread(target=mapper.display_loop, daemon=True)
        display_thread.start()
        
        print("ğŸ”„ç³»ç»Ÿè¿è¡Œä¸­ï¼Œç­‰å¾…æ•°æ®...")
        
        # ä¸»å¾ªç¯
        rospy.spin()
        
    except KeyboardInterrupt:
        print("\nâš ï¸æ”¶åˆ°ä¸­æ–­ä¿¡å·")
    except Exception as e:
        print(f"âŒä¸»ç¨‹åºé”™è¯¯: {e}")
    finally:
        if 'mapper' in locals():
            mapper.cleanup()
        print("ğŸ‘‹å¤šå±‚æ¬¡CLIP+SAMè¯­ä¹‰å»ºå›¾ç³»ç»Ÿé€€å‡º")


if __name__ == '__main__':
    main()
